<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>GClasses: GClasses::GIncrementalLearnerQAgent Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css">
<link href="doxygen.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.8 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="main.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
    </ul>
  </div>
  <div class="tabs">
    <ul>
      <li><a href="annotated.html"><span>Class&nbsp;List</span></a></li>
      <li><a href="classes.html"><span>Class&nbsp;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&nbsp;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&nbsp;Members</span></a></li>
    </ul>
  </div>
  <div class="navpath"><a class="el" href="namespace_g_classes.html">GClasses</a>::<a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html">GIncrementalLearnerQAgent</a>
  </div>
</div>
<div class="contents">
<h1>GClasses::GIncrementalLearnerQAgent Class Reference</h1><!-- doxytag: class="GClasses::GIncrementalLearnerQAgent" --><!-- doxytag: inherits="GClasses::GQLearner" -->This is an implementation of <a class="el" href="class_g_classes_1_1_g_q_learner.html" title="The base class of a Q-Learner. To use this class, there are four abstract methods...">GQLearner</a> that uses an incremental learner for its Q-table and a SoftMax (usually pick the best action, but sometimes randomly pick the action) strategy to balance between exploration vs exploitation. To use this class, you need to supply an incremental learner (see the comment for the constructor for more details) and to implement the GetRewardForLastAction method.  
<a href="#_details">More...</a>
<p>
<code>#include &lt;GReinforcement.h&gt;</code>
<p>
<div class="dynheader">
Inheritance diagram for GClasses::GIncrementalLearnerQAgent:</div>
<div class="dynsection">

<p><center><img src="class_g_classes_1_1_g_incremental_learner_q_agent.png" usemap="#GClasses::GIncrementalLearnerQAgent_map" border="0" alt=""></center>
<map name="GClasses::GIncrementalLearnerQAgent_map">
<area href="class_g_classes_1_1_g_q_learner.html" alt="GClasses::GQLearner" shape="rect" coords="0,56,233,80">
<area href="class_g_classes_1_1_g_policy_learner.html" alt="GClasses::GPolicyLearner" shape="rect" coords="0,0,233,24">
</map>
</div>

<p>
<a href="class_g_classes_1_1_g_incremental_learner_q_agent-members.html">List of all members.</a><table border="0" cellpadding="0" cellspacing="0">
<tr><td></td></tr>
<tr><td colspan="2"><br><h2>Public Member Functions</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#27cec314cf5aef316b0eb6c5f1a2feac">GIncrementalLearnerQAgent</a> (<a class="el" href="class_g_classes_1_1smart__ptr.html">sp_relation</a> &amp;pObsControlRelation, <a class="el" href="class_g_classes_1_1_g_incremental_learner.html">GIncrementalLearner</a> *pQTable, int actionDims, double *pInitialState, <a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a> *pRand, <a class="el" href="class_g_classes_1_1_g_agent_action_iterator.html">GAgentActionIterator</a> *pActionIterator, double softMaxThresh)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">pQTable must be an incremental learner. If the relation for pQTable has n attributes, then the first (n-1) attributes refer to the sense (state) and action, and the last attribute refers to the Q-value (the current estimate of the utility of performing that action in that state). For actionDims, see the comment for <a class="el" href="class_g_classes_1_1_g_policy_learner.html#ae6d5bdc9c85eda3c2d03ce3f57cdd60" title="actionDims specifies how many dimensions are in the action vector. (For example,...">GPolicyLearner::GPolicyLearner</a>. pInitialState is the initial sense vector. If softMaxThresh is 0, it always picks a random action. If softMaxThresh is 1, it always picks the best action. For values in between, it does something in between.  <a href="#27cec314cf5aef316b0eb6c5f1a2feac"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#6ec404c29da1ce89b0b71e5eaef58386">~GIncrementalLearnerQAgent</a> ()</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#408da3ccfb79be4da4ce5b94e135417a">getQValue</a> (const double *pState, const double *pAction)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">See the comment for GQLearner::GetQValue.  <a href="#408da3ccfb79be4da4ce5b94e135417a"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#e02583c57303a86e45af9f631bbed665">setQValue</a> (const double *pState, const double *pAction, double qValue)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">See the comment for GQLearner::SetQValue.  <a href="#e02583c57303a86e45af9f631bbed665"></a><br></td></tr>
<tr><td colspan="2"><br><h2>Protected Member Functions</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#21ae8e8bae94fbc24d797f61f5cbc6c5">chooseAction</a> (const double *pSenses, double *pOutActions)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">This method picks the action during training. This method is called by refinePolicyAndChooseNextAction. (If it makes things easier, the agent may actually perform the action here, but it's a better practise to wait until refinePolicyAndChooseNextAction returns, because that keeps the "thinking" and "acting" stages separated from each other.) One way to pick the next action is to call GetQValue for all possible actions in the current state, and pick the one with the highest Q-value. But if you always pick the best action, you'll never discover things you don't already know about, so you need to find some balance between exploration and exploitation. One way to do this is to usually pick the best action, but sometimes pick a random action.  <a href="#21ae8e8bae94fbc24d797f61f5cbc6c5"></a><br></td></tr>
<tr><td colspan="2"><br><h2>Protected Attributes</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_g_classes_1_1_g_incremental_learner.html">GIncrementalLearner</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#d3970dbfa1f2c2bae7445bad7258d722">m_pQTable</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#f53f57da129856b8686a68671f02dcdd">m_pBuf</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#5212a0fb6c453cf0e743355b2714898f">m_softMaxThresh</a></td></tr>

</table>
<hr><a name="_details"></a><h2>Detailed Description</h2>
This is an implementation of <a class="el" href="class_g_classes_1_1_g_q_learner.html" title="The base class of a Q-Learner. To use this class, there are four abstract methods...">GQLearner</a> that uses an incremental learner for its Q-table and a SoftMax (usually pick the best action, but sometimes randomly pick the action) strategy to balance between exploration vs exploitation. To use this class, you need to supply an incremental learner (see the comment for the constructor for more details) and to implement the GetRewardForLastAction method. <hr><h2>Constructor &amp; Destructor Documentation</h2>
<a class="anchor" name="27cec314cf5aef316b0eb6c5f1a2feac"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::GIncrementalLearnerQAgent" ref="27cec314cf5aef316b0eb6c5f1a2feac" args="(sp_relation &amp;pObsControlRelation, GIncrementalLearner *pQTable, int actionDims, double *pInitialState, GRand *pRand, GAgentActionIterator *pActionIterator, double softMaxThresh)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">GClasses::GIncrementalLearnerQAgent::GIncrementalLearnerQAgent           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1smart__ptr.html">sp_relation</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>pObsControlRelation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_incremental_learner.html">GIncrementalLearner</a> *&nbsp;</td>
          <td class="paramname"> <em>pQTable</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>actionDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&nbsp;</td>
          <td class="paramname"> <em>pInitialState</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a> *&nbsp;</td>
          <td class="paramname"> <em>pRand</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_agent_action_iterator.html">GAgentActionIterator</a> *&nbsp;</td>
          <td class="paramname"> <em>pActionIterator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&nbsp;</td>
          <td class="paramname"> <em>softMaxThresh</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
pQTable must be an incremental learner. If the relation for pQTable has n attributes, then the first (n-1) attributes refer to the sense (state) and action, and the last attribute refers to the Q-value (the current estimate of the utility of performing that action in that state). For actionDims, see the comment for <a class="el" href="class_g_classes_1_1_g_policy_learner.html#ae6d5bdc9c85eda3c2d03ce3f57cdd60" title="actionDims specifies how many dimensions are in the action vector. (For example,...">GPolicyLearner::GPolicyLearner</a>. pInitialState is the initial sense vector. If softMaxThresh is 0, it always picks a random action. If softMaxThresh is 1, it always picks the best action. For values in between, it does something in between. 
<p>

</div>
</div><p>
<a class="anchor" name="6ec404c29da1ce89b0b71e5eaef58386"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::~GIncrementalLearnerQAgent" ref="6ec404c29da1ce89b0b71e5eaef58386" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual GClasses::GIncrementalLearnerQAgent::~GIncrementalLearnerQAgent           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<hr><h2>Member Function Documentation</h2>
<a class="anchor" name="21ae8e8bae94fbc24d797f61f5cbc6c5"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::chooseAction" ref="21ae8e8bae94fbc24d797f61f5cbc6c5" args="(const double *pSenses, double *pOutActions)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void GClasses::GIncrementalLearnerQAgent::chooseAction           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pSenses</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&nbsp;</td>
          <td class="paramname"> <em>pOutActions</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [protected, virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method picks the action during training. This method is called by refinePolicyAndChooseNextAction. (If it makes things easier, the agent may actually perform the action here, but it's a better practise to wait until refinePolicyAndChooseNextAction returns, because that keeps the "thinking" and "acting" stages separated from each other.) One way to pick the next action is to call GetQValue for all possible actions in the current state, and pick the one with the highest Q-value. But if you always pick the best action, you'll never discover things you don't already know about, so you need to find some balance between exploration and exploitation. One way to do this is to usually pick the best action, but sometimes pick a random action. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_q_learner.html#40f05909e96c2dd4990a6a242dcc6453">GClasses::GQLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="408da3ccfb79be4da4ce5b94e135417a"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::getQValue" ref="408da3ccfb79be4da4ce5b94e135417a" args="(const double *pState, const double *pAction)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual double GClasses::GIncrementalLearnerQAgent::getQValue           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pState</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pAction</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
See the comment for GQLearner::GetQValue. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_q_learner.html#85b97fc5300546db37e92098ddd069f9">GClasses::GQLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="e02583c57303a86e45af9f631bbed665"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::setQValue" ref="e02583c57303a86e45af9f631bbed665" args="(const double *pState, const double *pAction, double qValue)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void GClasses::GIncrementalLearnerQAgent::setQValue           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pState</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pAction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&nbsp;</td>
          <td class="paramname"> <em>qValue</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
See the comment for GQLearner::SetQValue. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_q_learner.html#3d03ef30220ecb29362a77515a51fb7e">GClasses::GQLearner</a>.</p>

</div>
</div><p>
<hr><h2>Member Data Documentation</h2>
<a class="anchor" name="f53f57da129856b8686a68671f02dcdd"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::m_pBuf" ref="f53f57da129856b8686a68671f02dcdd" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double* <a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#f53f57da129856b8686a68671f02dcdd">GClasses::GIncrementalLearnerQAgent::m_pBuf</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="d3970dbfa1f2c2bae7445bad7258d722"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::m_pQTable" ref="d3970dbfa1f2c2bae7445bad7258d722" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_g_classes_1_1_g_incremental_learner.html">GIncrementalLearner</a>* <a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#d3970dbfa1f2c2bae7445bad7258d722">GClasses::GIncrementalLearnerQAgent::m_pQTable</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="5212a0fb6c453cf0e743355b2714898f"></a><!-- doxytag: member="GClasses::GIncrementalLearnerQAgent::m_softMaxThresh" ref="5212a0fb6c453cf0e743355b2714898f" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double <a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html#5212a0fb6c453cf0e743355b2714898f">GClasses::GIncrementalLearnerQAgent::m_softMaxThresh</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
</div>
<hr size="1"><address style="text-align: right;"><small>Generated on Tue Nov 2 14:18:24 2010 for GClasses by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.8 </small></address>
</body>
</html>
