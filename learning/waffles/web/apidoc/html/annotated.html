<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>GClasses: Class List</title>
<link href="tabs.css" rel="stylesheet" type="text/css">
<link href="doxygen.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.8 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="main.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
    </ul>
  </div>
  <div class="tabs">
    <ul>
      <li class="current"><a href="annotated.html"><span>Class&nbsp;List</span></a></li>
      <li><a href="classes.html"><span>Class&nbsp;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&nbsp;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&nbsp;Members</span></a></li>
    </ul>
  </div>
</div>
<div class="contents">
<h1>Class List</h1>Here are the classes, structs, unions and interfaces with brief descriptions:<table>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_array_holder.html">GClasses::ArrayHolder&lt; T &gt;</a></td><td class="indexvalue">Just like <a class="el" href="class_g_classes_1_1_holder.html" title="This class is very similar to the standard C++ class auto_ptr, except it throws an...">Holder</a>, except for arrays </td></tr>
  <tr><td class="indexkey"><a class="el" href="struct_g_classes_1_1_complex_number.html">GClasses::ComplexNumber</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_file_holder.html">GClasses::FileHolder</a></td><td class="indexvalue">Closes a file when this object goes out of scope </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g2_d_region_graph.html">GClasses::G2DRegionGraph</a></td><td class="indexvalue">Implements a region adjacency graph for 2D images, and lets you merge similar regions to create a hierarchical breakdown of the image </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_action_path.html">GClasses::GActionPath</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_action_path_search.html">GClasses::GActionPathSearch</a></td><td class="indexvalue">This is the base class of search algorithms that can only perform a discreet set of actions (as opposed to jumping to anywhere in the search space), and seeks to minimize the error of a path of actions </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_action_path_state.html">GClasses::GActionPathState</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_activation_algebraic.html">GClasses::GActivationAlgebraic</a></td><td class="indexvalue">The hyperbolic tangent activation function </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_activation_arc_tan.html">GClasses::GActivationArcTan</a></td><td class="indexvalue">The arctan activation function </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_activation_bend.html">GClasses::GActivationBend</a></td><td class="indexvalue">This provides an alternative to using <a class="el" href="class_g_classes_1_1_g_activation_identity.html" title="Use this function when you do not want to squash the net. For example, using this...">GActivationIdentity</a> on the output layer for regression problems. It may add more power because it is non-linear, but like the identity function, its co-domain is the same as its domain </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_activation_bi_dir.html">GClasses::GActivationBiDir</a></td><td class="indexvalue">This is an output-layer activation function shaped like a sigmoid, but with both a co-domain and domain that spans the continuous values </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_activation_function.html">GClasses::GActivationFunction</a></td><td class="indexvalue">The base class for activation functions. Typically, this are sigmoid-shaped functions used to "squash" the output of a network node. These are typically used in conjunction with the <a class="el" href="class_g_classes_1_1_g_neural_net.html" title="An artificial neural network.">GNeuralNet</a> class </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_activation_identity.html">GClasses::GActivationIdentity</a></td><td class="indexvalue">Use this function when you do not want to squash the net. For example, using this activation function with a network that has no hidden layers makes a perceptron model. Also, it is common to use this activation function on the output layer for regression problems </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_activation_logistic.html">GClasses::GActivationLogistic</a></td><td class="indexvalue">The logistic activation function </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_activation_piecewise.html">GClasses::GActivationPiecewise</a></td><td class="indexvalue">This is an experimental activation function intended to reduce the required computation involved in inverting neural networks </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_activation_tan_h.html">GClasses::GActivationTanH</a></td><td class="indexvalue">The hyperbolic tangent activation function </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_agent_action_iterator.html">GClasses::GAgentActionIterator</a></td><td class="indexvalue">Iterates through all the actions that are valid in the current state. If actions are continuous or very numerous, this should sample valid actions in a random order. The caller may decide that it has sampled enough at any time </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_agglomerative_clusterer.html">GClasses::GAgglomerativeClusterer</a></td><td class="indexvalue">This merges each cluster with its closest neighbor. (The distance between clusters is computed as the distance between the closest members of the clusters times (n^b), where n is the total number of points from both clusters, and b is a balancing factor </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_agglomerative_transducer.html">GClasses::GAgglomerativeTransducer</a></td><td class="indexvalue">This is a semi-supervised agglomerative clusterer. It can only handle one output, and it must be nominal. All inputs must be continuous. Also, it assumes that all output values are represented in the training set </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_annealing.html">GClasses::GAnnealing</a></td><td class="indexvalue">This algorithm tries the current direction and a slightly perturbed direction at each step. If the perturbed direction resulted in faster improvement, it becomes the new current direction. As long as the current direction yields improvement, it accelerates, otherwise it decelerates </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_app.html">GClasses::GApp</a></td><td class="indexvalue">Contains some generally useful functions for launching applications </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_arff_attribute.html">GClasses::GArffAttribute</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_arff_relation.html">GClasses::GArffRelation</a></td><td class="indexvalue">ARFF = Attribute-Relation File Format. This stores richer information than <a class="el" href="class_g_classes_1_1_g_relation.html" title="Holds the metadata for a dataset, including which attributes are continuous or nominal...">GRelation</a>. This includes a name, a name for each attribute, and names for each supported nominal value </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_arg_reader.html">GClasses::GArgReader</a></td><td class="indexvalue">Parses command-line args and provides methods to conveniently process them </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_atomic_cycle_finder.html">GClasses::GAtomicCycleFinder</a></td><td class="indexvalue">This finds all of the atomic cycles (cycles that cannot be divided into two smaller cycles) in a graph </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_attribute_selector.html">GClasses::GAttributeSelector</a></td><td class="indexvalue">Generates subsets of data that contain only the most relevant features for predicting the labels. The train method of this class produces a ranked ordering of the feature attributes by training a single-layer neural network, and deselecting the weakest attribute until all attributes have been deselected. The transform method uses only the highest-ranked attributes </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_back_prop.html">GClasses::GBackProp</a></td><td class="indexvalue">This class performs backpropagation on a neural network. (It is a separate class, because it is only needed while training. There is no reason to waste this space after training is complete, or if you choose to use a different technique to train the neural network.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_back_prop_layer.html">GClasses::GBackPropLayer</a></td><td class="indexvalue">An internal class used by <a class="el" href="class_g_classes_1_1_g_back_prop.html" title="This class performs backpropagation on a neural network. (It is a separate class...">GBackProp</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_back_prop_neuron.html">GClasses::GBackPropNeuron</a></td><td class="indexvalue">An internal class used by <a class="el" href="class_g_classes_1_1_g_back_prop.html" title="This class performs backpropagation on a neural network. (It is a separate class...">GBackProp</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_back_prop_weight.html">GClasses::GBackPropWeight</a></td><td class="indexvalue">An internal class used by <a class="el" href="class_g_classes_1_1_g_back_prop.html" title="This class performs backpropagation on a neural network. (It is a separate class...">GBackProp</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_bag.html">GClasses::GBag</a></td><td class="indexvalue">BAG stands for bootstrap aggregator. It represents an ensemble of voting modelers. Each model is trained with a slightly different training set, which is produced by drawing randomly from the original training set with replacement until we have a new training set of the same size. Each model is given equal weight in the vote </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_baseline_learner.html">GClasses::GBaselineLearner</a></td><td class="indexvalue">Always outputs the label mean (for continuous labels) and the most common class (for nominal labels) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_bayesian_network_child_iterator.html">GClasses::GBayesianNetworkChildIterator</a></td><td class="indexvalue">Iterates through all the children of the specified node in a Bayesian network </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_bayesian_network_node.html">GClasses::GBayesianNetworkNode</a></td><td class="indexvalue">This is the base class for all nodes in a Bayesian network. Classes that inherit from this class must implement three pure virtual methods. Note that the <a class="el" href="class_g_classes_1_1_g_univariate_distribution.html" title="This is the base class for univariate distributions.">GUnivariateDistribution</a> class has an IsDiscrete and an IsSupported method, so if your class wraps a <a class="el" href="class_g_classes_1_1_g_univariate_distribution.html" title="This is the base class for univariate distributions.">GUnivariateDistribution</a> then two of them are taken care of for you. In order to implement ComputeLogLikelihood, your class will probably need references to its parent nodes so that it can obtain their values to use as parameters for its distribution. You can implement your network structure however you like. When you have your network set up, you're ready to use MCMC to infer values for the network. To do this, just create a loop that calls Sample on each node in the network, and the whole network should eventually converge to good values. (Also, you need to make <a class="el" href="class_g_classes_1_1_g_bayesian_network_child_iterator.html" title="Iterates through all the children of the specified node in a Bayesian network.">GBayesianNetworkChildIterator</a> work, which I haven't worked out yet.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_beta_distribution.html">GClasses::GBetaDistribution</a></td><td class="indexvalue">The Beta distribution </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_bits.html">GClasses::GBits</a></td><td class="indexvalue">Contains various functions for bit analysis </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_bit_table.html">GClasses::GBitTable</a></td><td class="indexvalue">Represents a table of bits </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_brandes_betweenness_centrality.html">GClasses::GBrandesBetweennessCentrality</a></td><td class="indexvalue">Computes the number of times that the shortest-path between every pair of points passes over each edge and vertex </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_breadth_first_unfolding.html">GClasses::GBreadthFirstUnfolding</a></td><td class="indexvalue">A manifold learning algorithm that reduces dimensionality in local neighborhoods, and then stitches the reduced local neighborhoods together using the Kabsch algorithm </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_brute_force_neighbor_finder.html">GClasses::GBruteForceNeighborFinder</a></td><td class="indexvalue">Finds neighbors by measuring the distance to all points. This one should work properly even if the distance metric does not support the triangle inequality </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_brute_force_search.html">GClasses::GBruteForceSearch</a></td><td class="indexvalue">This performs a brute force search with uniform sampling over the unit hypercube with increasing granularity. (Your target function should scale the candidate vectors as necessary to cover the desired space.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_bucket.html">GClasses::GBucket</a></td><td class="indexvalue">When Train is called, this performs cross-validation on the training set to determine which learner is the best. It then trains that learner with the entire training set </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_categorical_distribution.html">GClasses::GCategoricalDistribution</a></td><td class="indexvalue">This is a distribution that specifies a probability for each value in a set of nominal values </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_clusterer.html">GClasses::GClusterer</a></td><td class="indexvalue">The base class for clustering algorithms. Classes that inherit from this class must implement a method named "cluster" which performs clustering, and a method named "whichCluster" which reports which cluster the specified row is determined to be a member of </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_compressor.html">GClasses::GCompressor</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_const_string_hash_table.html">GClasses::GConstStringHashTable</a></td><td class="indexvalue">Hash table based on keys of constant strings (or at least strings that won't change during the lifetime of the hash table). It's a good idea to use a <a class="el" href="class_g_classes_1_1_g_heap.html" title="Provides a heap in which to put strings or whatever you need to store. If you need...">GHeap</a> in connection with this class </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_const_string_to_ints_hash_table.html">GClasses::GConstStringToIntsHashTable</a></td><td class="indexvalue">Hash table based on keys of constant strings (or at least strings that won't change during the lifetime of the hash table). It's a good idea to use a <a class="el" href="class_g_classes_1_1_g_heap.html" title="Provides a heap in which to put strings or whatever you need to store. If you need...">GHeap</a> in connection with this class </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_coord_vector_iterator.html">GClasses::GCoordVectorIterator</a></td><td class="indexvalue">An iterator for an n-dimensional coordinate vector. For example, suppose you have a 4-dimensional 2x3x2x1 grid, and you want to iterate through its coordinates: (0000, 0010, 0100, 0110, 0200, 0210, 1000, 1010, 1100, 1110, 1200, 1210). This class will iterate over coordinate vectors in this manner. (For 0-dimensional coordinate vectors, it behaves as though the origin is the only valid coordinate.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_cycle_cut.html">GClasses::GCycleCut</a></td><td class="indexvalue">This finds the shortcuts in a table of neighbors and replaces them with INVALID_INDEX </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_data.html">GClasses::GData</a></td><td class="indexvalue">Represents a matrix or a database table. Elements can be discrete or continuous. References a <a class="el" href="class_g_classes_1_1_g_relation.html" title="Holds the metadata for a dataset, including which attributes are continuous or nominal...">GRelation</a> object, which stores the meta-information about each column </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_data_array.html">GClasses::GDataArray</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_decision_tree.html">GClasses::GDecisionTree</a></td><td class="indexvalue">This is an efficient learning algorithm. It divides on the attributes that reduce entropy the most, or alternatively can make random divisions </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_dijkstra.html">GClasses::GDijkstra</a></td><td class="indexvalue">Finds the shortest path from an origin vertex to all other vertices. Implemented with a binary-heap priority-queue. If the graph is sparse on edges, it will run in about O(n log(n)) time. If the graph is dense, it runs in about O(n^2 log(n)) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_discrete_action_iterator.html">GClasses::GDiscreteActionIterator</a></td><td class="indexvalue">This is a simple and common action iterator that can be used when there is a discrete set of possible actions </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_discretize.html">GClasses::GDiscretize</a></td><td class="indexvalue">This transform uses buckets to convert continuous data into discrete data. It is common to use <a class="el" href="class_g_classes_1_1_g_filter.html" title="This class enables functionality similar to filters in Weka. It wraps a modeler and...">GFilter</a> to combine this with your favorite modeler (which only supports discrete values) to create a modeler that can also support continuous values as well </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_dissimilarity_metric.html">GClasses::GDissimilarityMetric</a></td><td class="indexvalue">This class enables you to define dissimilarity (distance) metrics between two vectors. pScaleFactors is an optional parameter (it can be NULL) that lets the calling class scale the significance of each dimension. Distance metrics that do not mix with this concept may simply ignore any scale factors. Typically, classes that use this should be able to assume that the triangle inequality will hold, but do not necessarily enforce the parallelogram law </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_distribution.html">GClasses::GDistribution</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_double_rect.html">GClasses::GDoubleRect</a></td><td class="indexvalue">Represents a rectangular region with doubles </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_dynamic_system_neighbor_finder.html">GClasses::GDynamicSystemNeighborFinder</a></td><td class="indexvalue">A neighbor finder that specializes in dynamical systems. It determines neighbors by searching for the shortest path of actions between observations, and computes the distance as the length of the path </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_empirical_gradient_descent.html">GClasses::GEmpiricalGradientDescent</a></td><td class="indexvalue">This algorithm does a gradient descent by feeling a small distance out in each dimension to measure the gradient. For efficiency reasons, it only measures the gradient in one dimension (which it cycles round-robin style) per iteration and uses the remembered gradient in the other dimensions </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_evolutionary_optimizer.html">GClasses::GEvolutionaryOptimizer</a></td><td class="indexvalue">Uses an evolutionary process to optimize a vector </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_extended_kalman_filter.html">GClasses::GExtendedKalmanFilter</a></td><td class="indexvalue">This is an implementation of the Extended Kalman Filter. This class is used by alternately calling advance and correct </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_file.html">GClasses::GFile</a></td><td class="indexvalue">Contains some useful routines for manipulating files </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_filter.html">GClasses::GFilter</a></td><td class="indexvalue">This class enables functionality similar to filters in Weka. It wraps a modeler and transforms data before it is passed to the modeler, and/or after the modeler passes data back. For example, suppose that you wish to use <a class="el" href="class_g_classes_1_1_g_naive_bayes.html" title="A naive Bayes classifier.">GNaiveBayes</a> (which only supports discrete attributes) with a dataset that contains continuous attributes. You could use this class to wrap <a class="el" href="class_g_classes_1_1_g_discretize.html" title="This transform uses buckets to convert continuous data into discrete data. It is...">GDiscretize</a> around <a class="el" href="class_g_classes_1_1_g_naive_bayes.html" title="A naive Bayes classifier.">GNaiveBayes</a> to create a naive bayes that can operate on both continuous and discrete data. As another example, if you have a modeler that only supports real attributes, you could wrap it with <a class="el" href="class_g_classes_1_1_g_nominal_to_cat.html" title="This is sort-of the opposite of discretize. It converts each nominal attribute to...">GNominalToCat</a> to create a modeler that can operate on nominal data too. Or, if your modeler expects values within a certain range, you could use <a class="el" href="class_g_classes_1_1_g_normalize.html" title="This transform scales and shifts continuous values to make them fall within a specified...">GNormalize</a> to ensure that the modeler receives values within that range while leaving the caller free to pass in values with whatever range it prefers </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_float_rect.html">GClasses::GFloatRect</a></td><td class="indexvalue">Represents a rectangular region with floats </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_floyd_warshall.html">GClasses::GFloydWarshall</a></td><td class="indexvalue">Computes the shortest-cost path between all pairs of vertices in a graph. Takes O(n^3) time </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_fourier.html">GClasses::GFourier</a></td><td class="indexvalue">Fourier transform </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_function.html">GClasses::GFunction</a></td><td class="indexvalue">This class represents a math function. (It might be used, for example, in a plotting tool.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_function_parser.html">GClasses::GFunctionParser</a></td><td class="indexvalue">This class parses math equations. (This is useful, for example, for plotting tools.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_gamma_distribution.html">GClasses::GGammaDistribution</a></td><td class="indexvalue">The Gamma distribution </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_graph_cut.html">GClasses::GGraphCut</a></td><td class="indexvalue">This implements an optimized max-flow/min-cut algorithm described in "An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision" by Boykov, Y. and Kolmogorov, V. This implementation assumes that edges are undirected </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_graph_cut_transducer.html">GClasses::GGraphCutTransducer</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_graph_edge_iterator.html">GClasses::GGraphEdgeIterator</a></td><td class="indexvalue">Iterates over the edges that connect to the specified node </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_hash_table.html">GClasses::GHashTable</a></td><td class="indexvalue">Implements a typical hash table. (It doesn't take ownership of the objects you add, so you must still delete them yourself.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_hash_table_base.html">GClasses::GHashTableBase</a></td><td class="indexvalue">The base class of hash tables </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_hash_table_enumerator.html">GClasses::GHashTableEnumerator</a></td><td class="indexvalue">This class iterates over the values in a hash table </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_heap.html">GClasses::GHeap</a></td><td class="indexvalue">Provides a heap in which to put strings or whatever you need to store. If you need to allocate space for a lot of small objects, it's much more efficient to use this class than the C++ heap. Plus, you can delete them all by simply deleting the heap. You can't, however, reuse the space for individual objects in this heap </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_hidden_markov_model.html">GClasses::GHiddenMarkovModel</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_hill_climber.html">GClasses::GHillClimber</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_histogram.html">GClasses::GHistogram</a></td><td class="indexvalue">Gathers values and puts them in bins </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_html.html">GClasses::GHtml</a></td><td class="indexvalue">This class is for parsing HTML files. It's designed to be very simple. This class might be useful, for example, for building a web-crawler or for extracting readable text from a web page </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_identity_function.html">GClasses::GIdentityFunction</a></td><td class="indexvalue">This is an implementation of the identity function. It might be useful, for example, as the observation function in a <a class="el" href="class_g_classes_1_1_g_recurrent_model.html" title="This class can be used to implement recurrent neural networks, or recurrent forms...">GRecurrentModel</a> if you want to create a Jordan network </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_image.html">GClasses::GImage</a></td><td class="indexvalue">Represents an image </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_incremental_learner.html">GClasses::GIncrementalLearner</a></td><td class="indexvalue">This is the base class of supervised learning algorithms that can learn one row at a time </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_incremental_learner_q_agent.html">GClasses::GIncrementalLearnerQAgent</a></td><td class="indexvalue">This is an implementation of <a class="el" href="class_g_classes_1_1_g_q_learner.html" title="The base class of a Q-Learner. To use this class, there are four abstract methods...">GQLearner</a> that uses an incremental learner for its Q-table and a SoftMax (usually pick the best action, but sometimes randomly pick the action) strategy to balance between exploration vs exploitation. To use this class, you need to supply an incremental learner (see the comment for the constructor for more details) and to implement the GetRewardForLastAction method </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_incremental_transform.html">GClasses::GIncrementalTransform</a></td><td class="indexvalue">This is the base class of algorithms that can transform data one row at a time without supervision </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_index_vec.html">GClasses::GIndexVec</a></td><td class="indexvalue">Useful functions for operating on vectors of indexes </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_instance_table.html">GClasses::GInstanceTable</a></td><td class="indexvalue">This represents a grid of values. It might be useful as a Q-table with Q-learning </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_inverse_gamma_distribution.html">GClasses::GInverseGammaDistribution</a></td><td class="indexvalue">The inverse Gamma distribution </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_isomap.html">GClasses::GIsomap</a></td><td class="indexvalue">Isomap. (A well-known manifold learning algorithm.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kd_tree.html">GClasses::GKdTree</a></td><td class="indexvalue">An efficient algorithm for finding neighbors </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel.html">GClasses::GKernel</a></td><td class="indexvalue">The base class for kernel functions. Classes which implement this must provide an "apply" method that applies the kernel to two vectors. Kernels may be combined together to form a more complex kernel, to which the kernel trick will still apply </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel_add.html">GClasses::GKernelAdd</a></td><td class="indexvalue">An addition kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel_exp.html">GClasses::GKernelExp</a></td><td class="indexvalue">The Exponential kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel_gaussian_r_b_f.html">GClasses::GKernelGaussianRBF</a></td><td class="indexvalue">A Gaussian RBF kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel_identity.html">GClasses::GKernelIdentity</a></td><td class="indexvalue">The identity kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel_machine.html">GClasses::GKernelMachine</a></td><td class="indexvalue">An experimental kernel machine. Currently this algorithm is not competitive with state-of-the-art kernel machines </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel_multiply.html">GClasses::GKernelMultiply</a></td><td class="indexvalue">A multiplication kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel_normalize.html">GClasses::GKernelNormalize</a></td><td class="indexvalue">A Normalizing kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel_polynomial.html">GClasses::GKernelPolynomial</a></td><td class="indexvalue">A polynomial kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel_pow.html">GClasses::GKernelPow</a></td><td class="indexvalue">A power kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel_scale.html">GClasses::GKernelScale</a></td><td class="indexvalue">A scalar kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_kernel_translate.html">GClasses::GKernelTranslate</a></td><td class="indexvalue">A translation kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_k_means.html">GClasses::GKMeans</a></td><td class="indexvalue">An implementation of the K-means clustering algorithm </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_k_medoids.html">GClasses::GKMedoids</a></td><td class="indexvalue">An implementation of the K-medoids clustering algorithm </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_k_n_n.html">GClasses::GKNN</a></td><td class="indexvalue">The k-Nearest Neighbor learning algorithm </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_learner_loader.html">GClasses::GLearnerLoader</a></td><td class="indexvalue">This class is for loading various learning algorithms from a Twt node. When any learning algorithm is saved, it calls MakeBaseTwtNode, which creates (among other things) a field named "class" which specifies the class name of the algorithm. This class contains methods that will recognize any of the classes in this library and load them. If it doesn't recognize a class, it will either return NULL or throw and exception, depending on the flags you pass to the constructor. Obviously this loader won't recognize any classes that you make. Therefore, you should overload the corresponding method in this class with a new method that will first recognize and load your classes, and then call these methods to handle other types </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_linear_programming.html">GClasses::GLinearProgramming</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_linear_regressor.html">GClasses::GLinearRegressor</a></td><td class="indexvalue">A linear regression algorithm. Only supports 1 label dim </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_l_l_e.html">GClasses::GLLE</a></td><td class="indexvalue">Locally Linear Embedding. (A well-known manifold learning algorithm.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_manifold.html">GClasses::GManifold</a></td><td class="indexvalue">This class stores static methods that are useful for manifold learning </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_manifold_learner.html">GClasses::GManifoldLearner</a></td><td class="indexvalue">This is the base class of manifold learning (aka non-linear dimensionality reducing) algorithms </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_manifold_neighbor_finder.html">GClasses::GManifoldNeighborFinder</a></td><td class="indexvalue">This class intelligently selects neighbors for each point in a dataset, such that the neighbors define a good neighborhood for manifold learning. A relaxation technique is used to ensure that neighbors lie on a consistent tangent-space while remaining close to the point. This makes manifold learning possible with difficult (somtimes even self-intersecting) manifolds </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_manifold_sculpting.html">GClasses::GManifoldSculpting</a></td><td class="indexvalue">Manifold Sculpting. A non-linear dimensionality reduction algorithm. (See Gashler, Michael S. and Ventura, Dan and Martinez, Tony. Iterative non-linear dimensionality reduction with manifold sculpting. In Advances in Neural Information Processing Systems 20, pages 513–520, MIT Press, Cambridge, MA, 2008.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_math.html">GClasses::GMath</a></td><td class="indexvalue">Provides some useful math functions </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_mean_margins_tree.html">GClasses::GMeanMarginsTree</a></td><td class="indexvalue">A <a class="el" href="class_g_classes_1_1_g_mean_margins_tree.html" title="A GMeanMarginsTree is similar a DecisionTree, except it divides as follows: It finds...">GMeanMarginsTree</a> is similar a DecisionTree, except it divides as follows: It finds the mean and principle component of the output vectors. It divides all the vectors into two groups, one that has a positive dot-product with the principle component (after subtracting the mean) and one that has a negative dot-product with the principle component (after subtracting the mean). Next it finds the average input vector for each of the two groups. Then it finds the mean and principle component of those two vectors. The dividing criteria for this node is to subtract the mean and then see whether the dot-product with the principle component is positive or negative </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_minkowski_distance.html">GClasses::GMinkowskiDistance</a></td><td class="indexvalue">Interpolates between manhattan distance (norm=1), Euclidean distance (norm=2), and Chebyshev distance (norm=infinity). Throws an exception if any of the attributes are nominal </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_mixed_relation.html">GClasses::GMixedRelation</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_mixture_of_gaussians.html">GClasses::GMixtureOfGaussians</a></td><td class="indexvalue">This class uses Expectency Maximization to find the mixture of Gaussians that best approximates the data in a specified real attribute of a data set </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_momentum_greedy_search.html">GClasses::GMomentumGreedySearch</a></td><td class="indexvalue">At each iteration this algorithm moves in only one dimension. If the situation doesn't improve it tries the opposite direction. If both directions are worse, it decreases the step size for that dimension, otherwise it increases the step size for that dimension </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_multivariate_normal_distribution.html">GClasses::GMultivariateNormalDistribution</a></td><td class="indexvalue">A multivariate Normal distribution. It can compute the likelihood of a specified vector, and can also generate random vectors from the distribution </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_naive_bayes.html">GClasses::GNaiveBayes</a></td><td class="indexvalue">A naive Bayes classifier </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_naive_instance.html">GClasses::GNaiveInstance</a></td><td class="indexvalue">This is an instance-based learner. Instead of finding the k-nearest neighbors of a feature vector, it finds the k-nearst neighbors in each dimension. That is, it finds n*k neighbors, considering each dimension independently. It then combines the label from all of these neighbors to make a prediction. Finding neighbors in this way makes it more robust to high-dimensional datasets. It tends to perform worse than k-nn in low-dimensional space, and better than k-nn in high-dimensional space. (It may be thought of as a cross between a k-nn instance learner and a Naive Bayes learner. It only supports continuous features and labels (so it is common to wrap it in a Categorize filter which will convert nominal features to a categorical distribution of continuous values) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_naive_m_l_e.html">GClasses::GNaiveMLE</a></td><td class="indexvalue">This modeler is very similar to Naive Bayes, except even simpler. It just counts the frequency of each output give each input. To generalize, it assumes conditional independence and computes the maximum likelihood output based on the training rows with similar input values </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_neighbor_finder.html">GClasses::GNeighborFinder</a></td><td class="indexvalue">Finds the k-nearest neighbors of each vector in a dataset </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_neighbor_finder_cache_wrapper.html">GClasses::GNeighborFinderCacheWrapper</a></td><td class="indexvalue">This wraps a neighbor finding algorithm. It caches the queries for neighbors for the purpose of improving runtime performance </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_neighbor_finder_generalizing.html">GClasses::GNeighborFinderGeneralizing</a></td><td class="indexvalue">Finds the k-nearest neighbors (in a dataset) of an arbitrary vector (which may or may not be in the dataset) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_neighbor_transducer.html">GClasses::GNeighborTransducer</a></td><td class="indexvalue">An instance-based transduction algorithm </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_neural_net.html">GClasses::GNeuralNet</a></td><td class="indexvalue">An artificial neural network </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_neural_net_inverse_layer.html">GClasses::GNeuralNetInverseLayer</a></td><td class="indexvalue">A helper class used by <a class="el" href="class_g_classes_1_1_g_neural_net_pseudo_inverse.html" title="Computes the pseudo-inverse of a neural network.">GNeuralNetPseudoInverse</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_neural_net_layer.html">GClasses::GNeuralNetLayer</a></td><td class="indexvalue">Represents a layer of neurons in a neural network </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_neural_net_pseudo_inverse.html">GClasses::GNeuralNetPseudoInverse</a></td><td class="indexvalue">Computes the pseudo-inverse of a neural network </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_neuron.html">GClasses::GNeuron</a></td><td class="indexvalue">Represents a single neuron in a neural network </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_node_hash_table.html">GClasses::GNodeHashTable</a></td><td class="indexvalue">This is a hash table that uses any object which inherits from <a class="el" href="class_g_classes_1_1_hash_table_node.html" title="Objects used with GNodeHashTable should inherit from this class. They must implement...">HashTableNode</a> as the key </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_noise_generator.html">GClasses::GNoiseGenerator</a></td><td class="indexvalue">Just generates Gaussian noise </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_nominal_to_cat.html">GClasses::GNominalToCat</a></td><td class="indexvalue">This is sort-of the opposite of discretize. It converts each nominal attribute to a categorical distribution by representing each value using the corresponding row of the identity matrix. For example, if a certain nominal attribute has 4 possible values, then a value of 3 would be encoded as the vector 0 0 1 0. When predictions are converted back to nominal values, the mode of the categorical distribution is used as the predicted value. (This is similar to Weka's NominalToBinaryFilter.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_normal_distribution.html">GClasses::GNormalDistribution</a></td><td class="indexvalue">This is the Normal (a.k.a. Gaussian) distribution </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_normalize.html">GClasses::GNormalize</a></td><td class="indexvalue">This transform scales and shifts continuous values to make them fall within a specified range </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_optimizer.html">GClasses::GOptimizer</a></td><td class="indexvalue">This is the base class of all search algorithms that can jump to any vector in the search space seek the vector that minimizes error </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_pair_product.html">GClasses::GPairProduct</a></td><td class="indexvalue">Generates data by computing the product of each pair of attributes. This is useful for augmenting data </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_parallel_optimizers.html">GClasses::GParallelOptimizers</a></td><td class="indexvalue">This class simplifies simultaneously solving several optimization problems </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_particle_swarm.html">GClasses::GParticleSwarm</a></td><td class="indexvalue">An optimization algorithm inspired by flocking birds </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_passive_console.html">GClasses::GPassiveConsole</a></td><td class="indexvalue">This class provides a non-blocking method for reading characters from stdin. (If there are no characters ready in stdin, it immediately returns ''.) The constructor sets flags on the console so that it passes characters to the stream immediately (instead of when Enter is pressed), and so that it doesn't echo the keys, and it makes stdin non-blocking. The destructor puts all those things back the way they were </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_p_c_a.html">GClasses::GPCA</a></td><td class="indexvalue">Principal Component Analysis. (Computes the principal components about the mean of the data when you call train. The transformed (reduced-dimensional) data will have a mean about the origin.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_p_c_a_rotate_only.html">GClasses::GPCARotateOnly</a></td><td class="indexvalue">Principle Component Analysis without the projection. It only rotates axes to align with the first few principal components </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_peach_agent.html">GClasses::GPeachAgent</a></td><td class="indexvalue">This is an experimental policy-learning algorithm. It's currently too slow to be practical </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_plot_label_spacer.html">GClasses::GPlotLabelSpacer</a></td><td class="indexvalue">If you need to place grid lines or labels at regular intervals (like 1000, 2000, 3000, 4000... or 20, 25, 30, 35... or 0, 2, 4, 6, 8, 10...) this class will help you pick where to place the labels so that there are a reasonable number of them, and they all land on nice label values </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_plot_label_spacer_logarithmic.html">GClasses::GPlotLabelSpacerLogarithmic</a></td><td class="indexvalue">Similar to <a class="el" href="class_g_classes_1_1_g_plot_label_spacer.html" title="If you need to place grid lines or labels at regular intervals (like 1000, 2000,...">GPlotLabelSpacer</a>, except for logarithmic grids. To plot in logarithmic space, set your plot window to have a range from log_e(min) to log_e(max). When you actually plot things, plot them at log_e(x), where x is the position of the thing you want to plot </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_plot_window.html">GClasses::GPlotWindow</a></td><td class="indexvalue">This class makes it easy to plot points and functions on 2D cartesian coordinates </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_poisson_distribution.html">GClasses::GPoissonDistribution</a></td><td class="indexvalue">The Poisson distribution </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_policy_learner.html">GClasses::GPolicyLearner</a></td><td class="indexvalue">This is the base class for algorithms that learn a policy </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_polynomial.html">GClasses::GPolynomial</a></td><td class="indexvalue">This regresses a multi-dimensional polynomial to fit the data </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_prediction.html">GClasses::GPrediction</a></td><td class="indexvalue">This class is used to represent the predicted distribution made by a supervised learning algorithm. (It is just a shallow wrapper around <a class="el" href="class_g_classes_1_1_g_distribution.html">GDistribution</a>.) It is used in conjunction with calls to <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#45504ebdf2af63db0a7472b705db4a81" title="Evaluate pIn and compute a prediction for pOut. pOut is expected to point to an array...">GSupervisedLearner::predictDistribution</a>. The predicted distributions will be either categorical distributions (for nominal values) or Normal distributions (for continuous values) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_priority_queue.html">GClasses::GPriorityQueue</a></td><td class="indexvalue">An implementation of a double-ended priority queue </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_priority_queue_entry.html">GClasses::GPriorityQueueEntry</a></td><td class="indexvalue">An internal class used by <a class="el" href="class_g_classes_1_1_g_priority_queue.html" title="An implementation of a double-ended priority queue.">GPriorityQueue</a>. You should not use this class directly </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_probe_search.html">GClasses::GProbeSearch</a></td><td class="indexvalue">This is somewhat of a multi-dimensional version of binary-search. It greedily probes the best choices first, but then starts trying the opposite choices at the higher divisions so that it can also handle non-monotonic target functions. Each iteration performs a binary (divide-and-conquer) search within the unit hypercube. (Your target function should scale the candidate vectors as necessary to cover the desired space.) Because the high-level divisions are typically less correlated with the quality of the final result than the low-level divisions, it searches through the space of possible "probes" by toggling choices in the order from high level to low level. In low-dimensional space, this algorithm tends to quickly find good solutions, especially if the target function is somewhat smooth. In high-dimensional space, the number of iterations to find a good solution seems to grow exponentially </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_q_learner.html">GClasses::GQLearner</a></td><td class="indexvalue">The base class of a Q-Learner. To use this class, there are four abstract methods you'll need to implement. See also the comment for <a class="el" href="class_g_classes_1_1_g_policy_learner.html" title="This is the base class for algorithms that learn a policy.">GPolicyLearner</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_rand.html">GClasses::GRand</a></td><td class="indexvalue">This is a 64-bit pseudo-random number generator </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_random_search.html">GClasses::GRandomSearch</a></td><td class="indexvalue">At each iteration, this tries a random vector from the unit hypercube. (Your target function should scale the candidate vectors as necessary to cover the desired space.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_rect.html">GClasses::GRect</a></td><td class="indexvalue">Represents a rectangular region with integers </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_recurrent_model.html">GClasses::GRecurrentModel</a></td><td class="indexvalue">This class can be used to implement recurrent neural networks, or recurrent forms of other supervised models </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_region_ajacency_graph.html">GClasses::GRegionAjacencyGraph</a></td><td class="indexvalue">The base class for region ajacency graphs. These are useful for breaking down an image into patches of similar color </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_region_area_iterator.html">GClasses::GRegionAreaIterator</a></td><td class="indexvalue">Iterates over all the pixels in an image that have the same color and are transitively adjacent. In other words, if you were to flood-fill a the specified point, this returns all the pixels that would be changed </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_region_border_iterator.html">GClasses::GRegionBorderIterator</a></td><td class="indexvalue">Iterates the border of a 2D region by running around the border and reporting the coordinates of each interior border pixel and the direction to the edge. It goes in a counter-clockwise direction </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_relation.html">GClasses::GRelation</a></td><td class="indexvalue">Holds the metadata for a dataset, including which attributes are continuous or nominal, and how many values each nominal attribute supports </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_release_data_holder.html">GClasses::GReleaseDataHolder</a></td><td class="indexvalue">This is a special holder that guarantees the data set will release all of its data before it is deleted </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_row_distance.html">GClasses::GRowDistance</a></td><td class="indexvalue">This uses Euclidean distance for continuous attributes, and Hamming distance for nominal attributes </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_row_distance_scaled.html">GClasses::GRowDistanceScaled</a></td><td class="indexvalue">This uses Euclidean distance for continuous attributes, and Hamming distance for nominal attributes </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_rubber_ball_swarm.html">GClasses::GRubberBallSwarm</a></td><td class="indexvalue">This is an algorithm for finding good starting points within a constrained optimization problem. It works by simulating "rubber balls" which bounce around inside the constrained region. After many iterations, they tend to be spread somewhat uniformly, even with very complex constrained shapes. The balls learn to approximate the shape of the shell, so if the room is wider than it is tall, the balls will learn to bounce sideways more often than vertically </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_sample_climber.html">GClasses::GSampleClimber</a></td><td class="indexvalue">This is a variant of empirical gradient descent that tries to estimate the gradient using a minimal number of samples. It is more efficient than empirical gradient descent, but it only works well if the optimization surface is quite locally linear </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_self_organizing_map.html">GClasses::GSelfOrganizingMap</a></td><td class="indexvalue">An implementation of a Kohonen map </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_sequence_neighbor_finder.html">GClasses::GSequenceNeighborFinder</a></td><td class="indexvalue">A simple neighbor-finder that reports the nearest neighbors in the sequence. (That is, the previous and next rows are the closest neighbors.) The distance is sequential distance to the neighbor (not squared) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_shortcut_pruner.html">GClasses::GShortcutPruner</a></td><td class="indexvalue">This finds the shortcuts in a table of neighbors and replaces them with INVALID_INDEX </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_signal_handler.html">GClasses::GSignalHandler</a></td><td class="indexvalue">Temporarily handles certain signals. (When this object is destroyed, it puts all the signal handlers back the way they were.) Periodically call "check" to see if a signal has occurred </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_soft_impulse_distribution.html">GClasses::GSoftImpulseDistribution</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_sparse_matrix.html">GClasses::GSparseMatrix</a></td><td class="indexvalue">This class simultaneously stores a row-compressed sparse matrix and a column-compressed sparse matrix. It updates both of them </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_sparse_matrix_element.html">GClasses::GSparseMatrixElement</a></td><td class="indexvalue">This is a helper class used internally by <a class="el" href="class_g_classes_1_1_g_sparse_matrix.html" title="This class simultaneously stores a row-compressed sparse matrix and a column-compressed...">GSparseMatrix</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_spin_lock.html">GClasses::GSpinLock</a></td><td class="indexvalue">A spin-lock for synchronization purposes </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_spin_lock_holder.html">GClasses::GSpinLockHolder</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_stemmer.html">GClasses::GStemmer</a></td><td class="indexvalue">This class just wraps the Porter Stemmer. It finds the stems of words. Examples: "cats"-&gt;"cat" "dogs"-&gt;"dog" "fries"-&gt;"fri" "fishes"-&gt;"fish" "pies"-&gt;"pi" "lovingly"-&gt;"lovingli" "candy"-&gt;"candi" "babies"-&gt;"babi" "bus"-&gt;"bu" "busses"-&gt;"buss" "women"-&gt;"women" "hasty"-&gt;"hasti" "hastily"-&gt;"hastili" "fly"-&gt;"fly" "kisses"-&gt;"kiss" "goes"-&gt;"goe" "brought"-&gt;"brought" As you can see the stems aren't always real words, but that's okay as long as it produces the same stem for words that have the same etymological roots. Even then it still isn't perfect (notice it got "bus" wrong), but it should still improve analysis somewhat in many cases </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_string_chopper.html">GClasses::GStringChopper</a></td><td class="indexvalue">This class chops a big string at word breaks so you can display it intelligently on multiple lines </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_sub_image_finder.html">GClasses::GSubImageFinder</a></td><td class="indexvalue">This class uses Fourier phase correlation to efficiently find sub-images within a larger image </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_sub_image_finder2.html">GClasses::GSubImageFinder2</a></td><td class="indexvalue">This class uses heuristics to find sub-images within a larger image. It is slower, but more stable than <a class="el" href="class_g_classes_1_1_g_sub_image_finder.html" title="This class uses Fourier phase correlation to efficiently find sub-images within a...">GSubImageFinder</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_supervised_learner.html">GClasses::GSupervisedLearner</a></td><td class="indexvalue">This is the base class of algorithms that learn with supervision and have an internal hypothesis model that allows them to generalize rows that were not available at training time </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_system_learner.html">GClasses::GSystemLearner</a></td><td class="indexvalue">This is the base class for algorithms that learn to model dynamical systems </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_target_function.html">GClasses::GTargetFunction</a></td><td class="indexvalue">The optimizer seeks to find values that minimize this target function </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_temp_buf_helper.html">GClasses::GTempBufHelper</a></td><td class="indexvalue">A helper class used by the GTEMPBUF macro </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_thread.html">GClasses::GThread</a></td><td class="indexvalue">A wrapper for PThreads on Linux and for some corresponding WIN32 api on Windows </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_time.html">GClasses::GTime</a></td><td class="indexvalue">Provides some time-related functions </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_transducer.html">GClasses::GTransducer</a></td><td class="indexvalue">This is the base class of supervised learning algorithms (that may or may not have an internal model allowing them to generalize rows that were not available at training time). Note that the literature typically refers to supervised learning algorithms that can't generalize (because they lack an internal hypothesis model) as "Semi-supervised". (You cannot generalize with a semi-supervised algorithm--you have to train again with the new rows.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_transform.html">GClasses::GTransform</a></td><td class="indexvalue">This is the base class of algorithms that transform data without supervision </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_transform_chainer.html">GClasses::GTransformChainer</a></td><td class="indexvalue">This wraps two unsupervised learners to make a single unsupervised learner that performs both transforms sequentially </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_two_way_incremental_transform.html">GClasses::GTwoWayIncrementalTransform</a></td><td class="indexvalue">This is the base class of algorithms that can transform data one row at a time without supervision, and can (un)transform a row back to its original form if necessary </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_twt_doc.html">GClasses::GTwtDoc</a></td><td class="indexvalue">Twt is a text-based data format, somewhat like XML. The major differences are: XML is bloated, slow, designed for human readability, feature-rich, and hard to fully implement. Twt is compact, fast, designed for simplicity of machine parsing, simple, and easy to fully implement. (Plus, <a class="el" href="class_g_classes_1_1_g_twt_node.html" title="Represents a single node in the DOM of a GTwtDoc.">GTwtNode</a> has methods that will convert to/from XML, so you're never stuck if you use Twt as your file format.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="struct_g_classes_1_1_g_twt_list.html">GClasses::GTwtList</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_twt_node.html">GClasses::GTwtNode</a></td><td class="indexvalue">Represents a single node in the DOM of a <a class="el" href="class_g_classes_1_1_g_twt_doc.html" title="Twt is a text-based data format, somewhat like XML. The major differences are: XML...">GTwtDoc</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_uniform_distribution.html">GClasses::GUniformDistribution</a></td><td class="indexvalue">This is a continuous uniform distribution </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_uniform_relation.html">GClasses::GUniformRelation</a></td><td class="indexvalue">A relation with a minimal memory footprint that assumes all attributes are continuous, or all of them are nominal and have the same number of possible values </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_univariate_distribution.html">GClasses::GUnivariateDistribution</a></td><td class="indexvalue">This is the base class for univariate distributions </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_unsupervised_back_prop.html">GClasses::GUnsupervisedBackProp</a></td><td class="indexvalue">A manifold learning algorithm that uses back-propagation to train a neural net model to map from low-dimensional space to high-dimensional space </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_vec.html">GClasses::GVec</a></td><td class="indexvalue">Contains some useful functions for operating on vectors </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_vocabulary.html">GClasses::GVocabulary</a></td><td class="indexvalue">This is a helper class which is useful for text-mining. It collects words, stems them, filters them through a list of stop-words, and assigns a discrete number to each word </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_word_iterator.html">GClasses::GWordIterator</a></td><td class="indexvalue">This iterates over the words in a block of text </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_g_word_stats.html">GClasses::GWordStats</a></td><td class="indexvalue">Stores statistics about each word in a <a class="el" href="class_g_classes_1_1_g_vocabulary.html" title="This is a helper class which is useful for text-mining. It collects words, stems...">GVocabulary</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="struct_g_classes_1_1_hash_bucket.html">GClasses::HashBucket</a></td><td class="indexvalue">This is an internal structure used by <a class="el" href="class_g_classes_1_1_g_hash_table.html" title="Implements a typical hash table. (It doesn&#39;t take ownership of the objects you...">GHashTable</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_hash_table_node.html">GClasses::HashTableNode</a></td><td class="indexvalue">Objects used with <a class="el" href="class_g_classes_1_1_g_node_hash_table.html" title="This is a hash table that uses any object which inherits from HashTableNode as the...">GNodeHashTable</a> should inherit from this class. They must implement two methods (to hash and compare the nodes) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_holder.html">GClasses::Holder&lt; T &gt;</a></td><td class="indexvalue">This class is very similar to the standard C++ class auto_ptr, except it throws an exception if you try to make a copy of it. This way, it will fail early if you use it in a manner that could result in non-deterministic behavior. (For example, if you create a vector of auto_ptrs, wierd things happen if an oom exception is thrown while resizing the buffer--part of the data will be lost when it reverts back to the original buffer. But if you make a vector of these, it will fail quickly, thus alerting you to the issue.) </td></tr>
  <tr><td class="indexkey"><a class="el" href="struct_g_classes_1_1_path_data.html">GClasses::PathData</a></td><td class="indexvalue">Helper struct to hold the results from GFile::ParsePath </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1smart__ptr.html">GClasses::smart_ptr&lt; T &gt;</a></td><td class="indexvalue">A reference-counting smart-pointer </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1smart__ptr__ref__counter.html">GClasses::smart_ptr_ref_counter&lt; T &gt;</a></td><td class="indexvalue">A helper class used by the <a class="el" href="class_g_classes_1_1smart__ptr.html" title="A reference-counting smart-pointer.">smart_ptr</a> class </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_g_classes_1_1_vector_of_pointers_holder.html">GClasses::VectorOfPointersHolder&lt; T &gt;</a></td><td class="indexvalue">Deletes all of the pointers in a vector when this object goes out of scope </td></tr>
</table>
</div>
<hr size="1"><address style="text-align: right;"><small>Generated on Tue Nov 2 14:18:23 2010 for GClasses by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.8 </small></address>
</body>
</html>
