<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>GClasses: GClasses::GNeuralNet Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css">
<link href="doxygen.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.8 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="main.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
    </ul>
  </div>
  <div class="tabs">
    <ul>
      <li><a href="annotated.html"><span>Class&nbsp;List</span></a></li>
      <li><a href="classes.html"><span>Class&nbsp;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&nbsp;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&nbsp;Members</span></a></li>
    </ul>
  </div>
  <div class="navpath"><a class="el" href="namespace_g_classes.html">GClasses</a>::<a class="el" href="class_g_classes_1_1_g_neural_net.html">GNeuralNet</a>
  </div>
</div>
<div class="contents">
<h1>GClasses::GNeuralNet Class Reference</h1><!-- doxytag: class="GClasses::GNeuralNet" --><!-- doxytag: inherits="GClasses::GIncrementalLearner" -->An artificial neural network.  
<a href="#_details">More...</a>
<p>
<code>#include &lt;GNeuralNet.h&gt;</code>
<p>
<div class="dynheader">
Inheritance diagram for GClasses::GNeuralNet:</div>
<div class="dynsection">

<p><center><img src="class_g_classes_1_1_g_neural_net.png" usemap="#GClasses::GNeuralNet_map" border="0" alt=""></center>
<map name="GClasses::GNeuralNet_map">
<area href="class_g_classes_1_1_g_incremental_learner.html" alt="GClasses::GIncrementalLearner" shape="rect" coords="0,112,190,136">
<area href="class_g_classes_1_1_g_supervised_learner.html" alt="GClasses::GSupervisedLearner" shape="rect" coords="0,56,190,80">
<area href="class_g_classes_1_1_g_transducer.html" alt="GClasses::GTransducer" shape="rect" coords="0,0,190,24">
</map>
</div>

<p>
<a href="class_g_classes_1_1_g_neural_net-members.html">List of all members.</a><table border="0" cellpadding="0" cellspacing="0">
<tr><td></td></tr>
<tr><td colspan="2"><br><h2>Public Types</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">enum &nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#3821c260c2cb0dbc64b6b0fbd0aabe84">TargetFunction</a> { <a class="el" href="class_g_classes_1_1_g_neural_net.html#3821c260c2cb0dbc64b6b0fbd0aabe846b9faea53545aa616825e2885f6816eb">squared_error</a>, 
<a class="el" href="class_g_classes_1_1_g_neural_net.html#3821c260c2cb0dbc64b6b0fbd0aabe849c238cea3a50aa79304e64ac443e991b">cross_entropy</a>, 
<a class="el" href="class_g_classes_1_1_g_neural_net.html#3821c260c2cb0dbc64b6b0fbd0aabe8492930df95118c1790c0dde33b8db00d1">root_cubed_error</a>
 }</td></tr>

<tr><td colspan="2"><br><h2>Public Member Functions</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#91bbdd88eb9f1855e478fd921b18ad8b">GNeuralNet</a> (<a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a> *pRand)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#aa32f6c0562e2436c9c7f52b99df5cde">GNeuralNet</a> (<a class="el" href="class_g_classes_1_1_g_twt_node.html">GTwtNode</a> *pNode, <a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a> *pRand)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Load from a text-format.  <a href="#aa32f6c0562e2436c9c7f52b99df5cde"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#090fea822a920c75c99389aae9b2ebc7">~GNeuralNet</a> ()</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual <a class="el" href="class_g_classes_1_1_g_twt_node.html">GTwtNode</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#1b0e9c9c17f8396138024f7bd4241c05">toTwt</a> (<a class="el" href="class_g_classes_1_1_g_twt_doc.html">GTwtDoc</a> *pDoc)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Saves the model to a text file. (This doesn't save the short-term memory used for incremental learning, so if you're doing "incremental" learning, it will wake up with amnesia when you load it again.).  <a href="#1b0e9c9c17f8396138024f7bd4241c05"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#547fccef6ec0f6aad4d380bc4f1a0ef8">featureDims</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">See the comment for <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#fc302a31e9d5ef741343cf5659ba9a28" title="Returns the number of feature dims. Throws an exception if the model has not yet...">GSupervisedLearner::featureDims</a>.  <a href="#547fccef6ec0f6aad4d380bc4f1a0ef8"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#926cf27b73c9fbed9136304a25122885">labelDims</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">See the comment for <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#7d5d50de55dd9838f1caeab6e172d5aa" title="Returns the number of label dims. Throws an exception if the model has not yet been...">GSupervisedLearner::labelDims</a>.  <a href="#926cf27b73c9fbed9136304a25122885"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#3abb685af4764fa0f0c34492799f91b1">setActivationFunction</a> (<a class="el" href="class_g_classes_1_1_g_activation_function.html">GActivationFunction</a> *pSF, bool hold)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Sets the activation function to use with all subsequently added layers. (Note that the activation function for the output layer is set when train or enableIncrementalLearning is called, so if you only wish to set the squshing function for the output layer, call this method after all hidden layers have been added, but before you call train.) If hold is true, then the neural network will hold on to this instance of the activation function and delete it when the neural network is deleted.  <a href="#3abb685af4764fa0f0c34492799f91b1"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#936fe45380201e99ce19e557e9a356fc">addLayer</a> (int nNodes)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Adds a hidden layer to the network. (The first hidden layer that you add will be adjacent to the input features. The last hidden layer that you add will be adjacent to the output layer.).  <a href="#936fe45380201e99ce19e557e9a356fc"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">size_t&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#449d358ad9956d5fc61db21efe1a3942">layerCount</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Returns the number of layers in this neural network. (Every network has at least one output layer, plus all of the hidden layers that you add by calling addLayer.).  <a href="#449d358ad9956d5fc61db21efe1a3942"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_g_classes_1_1_g_neural_net_layer.html">GNeuralNetLayer</a> &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#81c093fb25cbd640578099b715dc8a50">getLayer</a> (int layer)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Returns a reference to the specified layer.  <a href="#81c093fb25cbd640578099b715dc8a50"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#ecbaee8213cc4cdf64aff5842ac7f255">addNode</a> (size_t layer)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Adds a new node at the end of the specified layer. (The new node is initialized with small weights, so this operation should initially have little impact on predictions.).  <a href="#ecbaee8213cc4cdf64aff5842ac7f255"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#d7aba05b75ee2d29d67bab3db14f5af7">dropNode</a> (size_t layer, size_t node)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Removes the specified node from the specified layer. (An exception will be thrown the layer only has one node.).  <a href="#d7aba05b75ee2d29d67bab3db14f5af7"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_g_classes_1_1_g_back_prop.html">GBackProp</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#fde11cca4167200c72b6567ef03b50fa">backProp</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Returns the backprop object associated with this neural net (if there is one).  <a href="#fde11cca4167200c72b6567ef03b50fa"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#0f3e41a0e0e9e363e2398de2ba231f33">setValidationPortion</a> (double d)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Set the portion of the data that will be used for validation. If the value is 0, then all of the data is used for both training and validation.  <a href="#0f3e41a0e0e9e363e2398de2ba231f33"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">size_t&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#62993759833ca851fd776a5ac0baa2b9">countWeights</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Counts the number of weights in the network. (This value is not cached, so you should cache it rather than frequently call this method.).  <a href="#62993759833ca851fd776a5ac0baa2b9"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#85534d9115c3ab715d3043715e6c2145">perturbAllWeights</a> (double deviation)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Perturbs all weights in the network by a random normal offset with the specified deviation.  <a href="#85534d9115c3ab715d3043715e6c2145"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#9ce8cc5daefb05c2fc60b2c2f1257952">clipWeights</a> (double max)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Clips all non-bias weights to fall within the range [-max, max].  <a href="#9ce8cc5daefb05c2fc60b2c2f1257952"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#bc535e04fa4d64fa2c641d3c1f5a058f">decayWeights</a> (double lambda, double gamma=1.0)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Multiplies all non-bias weights by (1.0 - (learning_rate * lambda)), starting with the output layer, and ending with the first hidden layer. Typical values for lambda are small (like 0.001.) After each layer, the value of lambda is multiplied by gamma. (If gamma is greater than 1.0, then weights in hidden layers will decay faster, and if gamma is less than 1.0, then weights in hidden layers will decay slower.) It may be significant to note that if a regularizing penalty is added to the error of lambda times the sum-squared values of non-bias weights, then on-line weight updating works out to the same as decaying the weights after each application of back-prop.  <a href="#bc535e04fa4d64fa2c641d3c1f5a058f"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#40d6982c5565bdb16711ab0361471614">learningRate</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Returns the current learning rate.  <a href="#40d6982c5565bdb16711ab0361471614"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#bfdf6d4186899d5f508d32a336903594">setLearningRate</a> (double d)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Set the learning rate.  <a href="#bfdf6d4186899d5f508d32a336903594"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#dfaf081a7b17988e868532ddd621a6e0">trainEpoch</a> (<a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *pTrainingData)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Performs a single epoch of training.  <a href="#dfaf081a7b17988e868532ddd621a6e0"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#aae62462d9be256a2a260c17eef4afbc">momentum</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Returns the current momentum value.  <a href="#aae62462d9be256a2a260c17eef4afbc"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#3294a63458679248ed777c433ae3c66d">setMomentum</a> (double d)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Momentum has the effect of speeding convergence and helping the gradient descent algorithm move past some local minimums.  <a href="#3294a63458679248ed777c433ae3c66d"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#f383c68fff7a133b616d93020180015a">setMinImprovement</a> (double d)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Specifies the minimum improvement (as a ratio) that must be made since the last validation check for trainingn to continue. (For example, if the mean squared error at the previous validation check was 50, and the mean squared error at the current validation check is 49, then training will stop if d is &gt; 0.02.).  <a href="#f383c68fff7a133b616d93020180015a"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#70096fc13b46b267fa137657f7b7a14c">setIterationsPerValidationCheck</a> (int n)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Sets the number of iterations that will be performed before each time the network is tested again with the validation set to determine if we have a better best-set of weights, and whether or not it's achieved the termination condition yet. (An iteration is defined as a single pass through all rows in the training set.).  <a href="#70096fc13b46b267fa137657f7b7a14c"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#3942e81858018f7977e97a99fd222254">setBackPropTargetFunction</a> (<a class="el" href="class_g_classes_1_1_g_neural_net.html#3821c260c2cb0dbc64b6b0fbd0aabe84">TargetFunction</a> eTF)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Specify the target function to use for back-propagation. The default is squared_error. cross_entropy tends to be faster, and is well-suited for classification tasks.  <a href="#3942e81858018f7977e97a99fd222254"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#934efa27b8fb84f51953d725e092700b">train</a> (<a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *pData, int labelDims)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Splits the provided data into a training and validation set and trains the network. To set the ratio, use SetTrainingPortion.  <a href="#934efa27b8fb84f51953d725e092700b"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#30df9f3dbc0eee98c592acc990dcf130">trainSparse</a> (<a class="el" href="class_g_classes_1_1_g_sparse_matrix.html">GSparseMatrix</a> *pData, int labelDims)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">See the comment for <a class="el" href="class_g_classes_1_1_g_incremental_learner.html#72b760cfd5f35e6ba73203c65e5a13e3" title="Train using a sparse matrix. (Typically, implementations of this method will iterate...">GIncrementalLearner::trainSparse</a> Assumes all attributes are continuous.  <a href="#30df9f3dbc0eee98c592acc990dcf130"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#3248753d965401e286e7c1faa6f6a706">enableIncrementalLearning</a> (<a class="el" href="class_g_classes_1_1smart__ptr.html">sp_relation</a> &amp;pRelation, int labelDims, double *pMins, double *pRanges)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">See the comment for <a class="el" href="class_g_classes_1_1_g_incremental_learner.html#c7c0a47f10dd10ef5cccab601e91ff37" title="You must call this method before you call trainIncremental pMins specifies the minimum...">GIncrementalLearner::enableIncrementalLearning</a>.  <a href="#3248753d965401e286e7c1faa6f6a706"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#17ba800554377c60acf256741cabe82c">trainIncremental</a> (const double *pIn, const double *pOut)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">See the comment for <a class="el" href="class_g_classes_1_1_g_incremental_learner.html#19b2d9edab4fbcb0fca825bc070dd156" title="Pass a single input row and the corresponding label to incrementally train this model...">GIncrementalLearner::trainIncremental</a>.  <a href="#17ba800554377c60acf256741cabe82c"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#38d68ba2a901c40324d1c5eff2a15e59">predictDistribution</a> (const double *pIn, <a class="el" href="class_g_classes_1_1_g_prediction.html">GPrediction</a> *pOut)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">See the comment for <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#45504ebdf2af63db0a7472b705db4a81" title="Evaluate pIn and compute a prediction for pOut. pOut is expected to point to an array...">GSupervisedLearner::predictDistribution</a>.  <a href="#38d68ba2a901c40324d1c5eff2a15e59"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#3b4eedbe12ff0e31974d8b53da9ee85b">predict</a> (const double *pIn, double *pOut)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">See the comment for <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#369f9d2f11fae74b8183f656d9ca74c6" title="Evaluate pIn and compute a prediction for pOut.">GSupervisedLearner::predict</a>.  <a href="#3b4eedbe12ff0e31974d8b53da9ee85b"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#034d339a9946207f5cf20478c96ffdad">clear</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">See the comment for <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#a4df3b300514838026aa3eda33315fb4" title="Discards all training for the purpose of freeing memory. If you call this method...">GSupervisedLearner::clear</a>.  <a href="#034d339a9946207f5cf20478c96ffdad"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#28cc2607f76d137b3d3bfe9c8852bc4c">trainWithValidation</a> (<a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *pTrainingData, <a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *pValidationData, int labelDims)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Train the network until the termination condition is met. Returns the number of epochs required to train it.  <a href="#28cc2607f76d137b3d3bfe9c8852bc4c"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#ed2999a007c3fcf02e484e9d87c627d5">releaseTrainingJunk</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Some extra junk is allocated when training to make it efficient. This method is called when training is done to get rid of that extra junk.  <a href="#ed2999a007c3fcf02e484e9d87c627d5"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#58402b48c8fa31a7a634b3ad2ea7ec72">internalTrainingData</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Gets the internal training data set.  <a href="#58402b48c8fa31a7a634b3ad2ea7ec72"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#061bbccb9e77b571829aea44e0337c99">internalValidationData</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Gets the internal validation data set.  <a href="#061bbccb9e77b571829aea44e0337c99"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#c7b2fc220e96389fc0cb4d3694d40a02">setWeights</a> (const double *pWeights)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Sets all the weights from an array of doubles. The number of doubles in the array can be determined by calling GetWeightCount().  <a href="#c7b2fc220e96389fc0cb4d3694d40a02"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#f2de389bfa8fc82fc4c4131b277b1f3b">copyWeights</a> (<a class="el" href="class_g_classes_1_1_g_neural_net.html">GNeuralNet</a> *pOther)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Copy the weights from pOther. It is assumed (but not checked) that pOther has the same network structure as this neural network.  <a href="#f2de389bfa8fc82fc4c4131b277b1f3b"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#93626ba454ef61f90b87df71a267b43e">copyStructure</a> (<a class="el" href="class_g_classes_1_1_g_neural_net.html">GNeuralNet</a> *pOther)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Copies the layers, nodes, and settings from pOther (but not the weights). enableIncrementalLearning must have been called on pOther so that it has a complete structure.  <a href="#93626ba454ef61f90b87df71a267b43e"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#48f738fa5bc10067b2901cc12624e3bb">weights</a> (double *pOutWeights)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Serializes the network weights into an array of doubles. The number of doubles in the array can be determined by calling GetWeightCount().  <a href="#48f738fa5bc10067b2901cc12624e3bb"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#9eb2d76976a334859f415ec494051a78">inputsToInternal</a> (const double *pExternal, double *pInternal)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Convert all the input values to the internal representation.  <a href="#9eb2d76976a334859f415ec494051a78"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#d8c239a22c8e348f92f5fc1713a85808">outputsToInternal</a> (const double *pExternal, double *pInternal)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Convert all the output values to the internal representation pExternal points to the first external output value (so just the output part of the row). pInternal points to the first internal input value (so it's the whole internal row).  <a href="#d8c239a22c8e348f92f5fc1713a85808"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#4c160f9a8f9c33fe7cd79720be6a421c">outputsToExternal</a> (<a class="el" href="class_g_classes_1_1_g_prediction.html">GPrediction</a> *pExternal)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Convert the internal output values to the external representation.  <a href="#4c160f9a8f9c33fe7cd79720be6a421c"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#e414e0b24c63e5a376d3ddaa0a0564b4">getRand</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Returns the pseudo-random number generator associated with this object.  <a href="#e414e0b24c63e5a376d3ddaa0a0564b4"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#09c2968b2e273de0cd0206e9b49c5349">forwardProp</a> (const double *pRow)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Evaluates a feature vector. (The results will be in the nodes of the output layer.).  <a href="#09c2968b2e273de0cd0206e9b49c5349"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#e87bc9372fb5705cf3bde1481faef090">copyPrediction</a> (double *pOut)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">This method assumes forwardProp has been called. It copies the predicted vector into pOut.  <a href="#e87bc9372fb5705cf3bde1481faef090"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#4fc5b7d1e52af80cd3676a759e1bccc2">sumSquaredPredictionError</a> (const double *pTarget)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">This method assumes forwardProp has been called. It computes the sum squared prediction error with the specified target vector.  <a href="#4fc5b7d1e52af80cd3676a759e1bccc2"></a><br></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#2d02f321a6232f3b1640504c235655c9">setErrorOnOutputLayer</a> (const double *pTarget, <a class="el" href="class_g_classes_1_1_g_neural_net.html#3821c260c2cb0dbc64b6b0fbd0aabe84">TargetFunction</a> eTargetFunction=squared_error)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">This method assumes that forwardProp has already been called. (Note that the predict method calls forwardProp). It computes the error values at each node in the output layer. After calling this method, it is typical to call <a class="el" href="class_g_classes_1_1_g_neural_net.html#fde11cca4167200c72b6567ef03b50fa" title="Returns the backprop object associated with this neural net (if there is one).">backProp()</a>-&gt;backpropagate(), to compute the error on the hidden nodes, and then to call <a class="el" href="class_g_classes_1_1_g_neural_net.html#fde11cca4167200c72b6567ef03b50fa" title="Returns the backprop object associated with this neural net (if there is one).">backProp()</a>-&gt;descendGradient to update the weights. pTarget contains the target values for the ouptut nodes.  <a href="#2d02f321a6232f3b1640504c235655c9"></a><br></td></tr>
<tr><td colspan="2"><br><h2>Static Public Member Functions</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">static void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#b0b1fe168491730483217ccccf6cf374">test</a> ()</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Performs unit tests for this class. Throws an exception if there is a failure.  <a href="#b0b1fe168491730483217ccccf6cf374"></a><br></td></tr>
<tr><td colspan="2"><br><h2>Protected Member Functions</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#ff4b7ef75957d163158c37a3f30738da">validationSquaredError</a> (<a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *pValidationData)</td></tr>

<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Measures the sum squared error against the specified dataset.  <a href="#ff4b7ef75957d163158c37a3f30738da"></a><br></td></tr>
<tr><td colspan="2"><br><h2>Protected Attributes</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">std::vector&lt; <a class="el" href="class_g_classes_1_1_g_neural_net_layer.html">GNeuralNetLayer</a> &gt;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#92c3817e46a09eb23dc7e8b511c527e0">m_layers</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#c30372cfb8f73597234cc54df72d5d60">m_pRand</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_g_classes_1_1_g_back_prop.html">GBackProp</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#cc73a2f7b836adec6ce7fadcf15520f5">m_pBackProp</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#0efb3a73fccebcb8b16dfc9254c7c021">m_featureDims</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#78f1a3faf8095eeb5b95626dbda5caea">m_labelDims</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">std::vector<br class="typebreak">
&lt; <a class="el" href="class_g_classes_1_1_g_activation_function.html">GActivationFunction</a> * &gt;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#b2b1de8a28c9229f2fb42f072178b141">m_activationFunctions</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_g_classes_1_1_g_activation_function.html">GActivationFunction</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#266df7e66c43efb5413edef8c1bd2356">m_pActivationFunction</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#860d67144206d666e8823554ad59e004">m_learningRate</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#a91d9ff41ea8cf0bf9aebd5c38eaffc4">m_momentum</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#df2792b6c57bc14e309f4d3f57bd259c">m_validationPortion</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#1373365847eba4087b4578a781455bd4">m_minImprovement</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#e441221ff1fad1d68fc4345419149ed1">m_epochsPerValidationCheck</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_g_classes_1_1_g_neural_net.html#3821c260c2cb0dbc64b6b0fbd0aabe84">TargetFunction</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#7ba6d45b553272733e346939220d7557">m_backPropTargetFunction</a></td></tr>

<tr><td colspan="2"><br><h2>Friends</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">class&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_g_classes_1_1_g_neural_net.html#fd0d02db90315bd84b88cc5924a29053">GBackProp</a></td></tr>

</table>
<hr><a name="_details"></a><h2>Detailed Description</h2>
An artificial neural network. <hr><h2>Member Enumeration Documentation</h2>
<a class="anchor" name="3821c260c2cb0dbc64b6b0fbd0aabe84"></a><!-- doxytag: member="GClasses::GNeuralNet::TargetFunction" ref="3821c260c2cb0dbc64b6b0fbd0aabe84" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="class_g_classes_1_1_g_neural_net.html#3821c260c2cb0dbc64b6b0fbd0aabe84">GClasses::GNeuralNet::TargetFunction</a>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
<dl compact><dt><b>Enumerator: </b></dt><dd>
<table border="0" cellspacing="2" cellpadding="0">
<tr><td valign="top"><em><a class="anchor" name="3821c260c2cb0dbc64b6b0fbd0aabe846b9faea53545aa616825e2885f6816eb"></a><!-- doxytag: member="squared_error" ref="3821c260c2cb0dbc64b6b0fbd0aabe846b9faea53545aa616825e2885f6816eb" args="" -->squared_error</em>&nbsp;</td><td>
</td></tr>
<tr><td valign="top"><em><a class="anchor" name="3821c260c2cb0dbc64b6b0fbd0aabe849c238cea3a50aa79304e64ac443e991b"></a><!-- doxytag: member="cross_entropy" ref="3821c260c2cb0dbc64b6b0fbd0aabe849c238cea3a50aa79304e64ac443e991b" args="" -->cross_entropy</em>&nbsp;</td><td>
(default) best for regression </td></tr>
<tr><td valign="top"><em><a class="anchor" name="3821c260c2cb0dbc64b6b0fbd0aabe8492930df95118c1790c0dde33b8db00d1"></a><!-- doxytag: member="root_cubed_error" ref="3821c260c2cb0dbc64b6b0fbd0aabe8492930df95118c1790c0dde33b8db00d1" args="" -->root_cubed_error</em>&nbsp;</td><td>
best for classification </td></tr>
</table>
</dl>

</div>
</div><p>
<hr><h2>Constructor &amp; Destructor Documentation</h2>
<a class="anchor" name="91bbdd88eb9f1855e478fd921b18ad8b"></a><!-- doxytag: member="GClasses::GNeuralNet::GNeuralNet" ref="91bbdd88eb9f1855e478fd921b18ad8b" args="(GRand *pRand)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">GClasses::GNeuralNet::GNeuralNet           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a> *&nbsp;</td>
          <td class="paramname"> <em>pRand</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="aa32f6c0562e2436c9c7f52b99df5cde"></a><!-- doxytag: member="GClasses::GNeuralNet::GNeuralNet" ref="aa32f6c0562e2436c9c7f52b99df5cde" args="(GTwtNode *pNode, GRand *pRand)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">GClasses::GNeuralNet::GNeuralNet           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_twt_node.html">GTwtNode</a> *&nbsp;</td>
          <td class="paramname"> <em>pNode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a> *&nbsp;</td>
          <td class="paramname"> <em>pRand</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Load from a text-format. 
<p>

</div>
</div><p>
<a class="anchor" name="090fea822a920c75c99389aae9b2ebc7"></a><!-- doxytag: member="GClasses::GNeuralNet::~GNeuralNet" ref="090fea822a920c75c99389aae9b2ebc7" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual GClasses::GNeuralNet::~GNeuralNet           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<hr><h2>Member Function Documentation</h2>
<a class="anchor" name="936fe45380201e99ce19e557e9a356fc"></a><!-- doxytag: member="GClasses::GNeuralNet::addLayer" ref="936fe45380201e99ce19e557e9a356fc" args="(int nNodes)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::addLayer           </td>
          <td>(</td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>nNodes</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Adds a hidden layer to the network. (The first hidden layer that you add will be adjacent to the input features. The last hidden layer that you add will be adjacent to the output layer.). 
<p>

</div>
</div><p>
<a class="anchor" name="ecbaee8213cc4cdf64aff5842ac7f255"></a><!-- doxytag: member="GClasses::GNeuralNet::addNode" ref="ecbaee8213cc4cdf64aff5842ac7f255" args="(size_t layer)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::addNode           </td>
          <td>(</td>
          <td class="paramtype">size_t&nbsp;</td>
          <td class="paramname"> <em>layer</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Adds a new node at the end of the specified layer. (The new node is initialized with small weights, so this operation should initially have little impact on predictions.). 
<p>

</div>
</div><p>
<a class="anchor" name="fde11cca4167200c72b6567ef03b50fa"></a><!-- doxytag: member="GClasses::GNeuralNet::backProp" ref="fde11cca4167200c72b6567ef03b50fa" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_g_classes_1_1_g_back_prop.html">GBackProp</a>* GClasses::GNeuralNet::backProp           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Returns the backprop object associated with this neural net (if there is one). 
<p>

</div>
</div><p>
<a class="anchor" name="034d339a9946207f5cf20478c96ffdad"></a><!-- doxytag: member="GClasses::GNeuralNet::clear" ref="034d339a9946207f5cf20478c96ffdad" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void GClasses::GNeuralNet::clear           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline, virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
See the comment for <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#a4df3b300514838026aa3eda33315fb4" title="Discards all training for the purpose of freeing memory. If you call this method...">GSupervisedLearner::clear</a>. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#a4df3b300514838026aa3eda33315fb4">GClasses::GSupervisedLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="9ce8cc5daefb05c2fc60b2c2f1257952"></a><!-- doxytag: member="GClasses::GNeuralNet::clipWeights" ref="9ce8cc5daefb05c2fc60b2c2f1257952" args="(double max)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::clipWeights           </td>
          <td>(</td>
          <td class="paramtype">double&nbsp;</td>
          <td class="paramname"> <em>max</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Clips all non-bias weights to fall within the range [-max, max]. 
<p>

</div>
</div><p>
<a class="anchor" name="e87bc9372fb5705cf3bde1481faef090"></a><!-- doxytag: member="GClasses::GNeuralNet::copyPrediction" ref="e87bc9372fb5705cf3bde1481faef090" args="(double *pOut)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::copyPrediction           </td>
          <td>(</td>
          <td class="paramtype">double *&nbsp;</td>
          <td class="paramname"> <em>pOut</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method assumes forwardProp has been called. It copies the predicted vector into pOut. 
<p>

</div>
</div><p>
<a class="anchor" name="93626ba454ef61f90b87df71a267b43e"></a><!-- doxytag: member="GClasses::GNeuralNet::copyStructure" ref="93626ba454ef61f90b87df71a267b43e" args="(GNeuralNet *pOther)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::copyStructure           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_neural_net.html">GNeuralNet</a> *&nbsp;</td>
          <td class="paramname"> <em>pOther</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Copies the layers, nodes, and settings from pOther (but not the weights). enableIncrementalLearning must have been called on pOther so that it has a complete structure. 
<p>

</div>
</div><p>
<a class="anchor" name="f2de389bfa8fc82fc4c4131b277b1f3b"></a><!-- doxytag: member="GClasses::GNeuralNet::copyWeights" ref="f2de389bfa8fc82fc4c4131b277b1f3b" args="(GNeuralNet *pOther)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::copyWeights           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_neural_net.html">GNeuralNet</a> *&nbsp;</td>
          <td class="paramname"> <em>pOther</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Copy the weights from pOther. It is assumed (but not checked) that pOther has the same network structure as this neural network. 
<p>

</div>
</div><p>
<a class="anchor" name="62993759833ca851fd776a5ac0baa2b9"></a><!-- doxytag: member="GClasses::GNeuralNet::countWeights" ref="62993759833ca851fd776a5ac0baa2b9" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">size_t GClasses::GNeuralNet::countWeights           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Counts the number of weights in the network. (This value is not cached, so you should cache it rather than frequently call this method.). 
<p>

</div>
</div><p>
<a class="anchor" name="bc535e04fa4d64fa2c641d3c1f5a058f"></a><!-- doxytag: member="GClasses::GNeuralNet::decayWeights" ref="bc535e04fa4d64fa2c641d3c1f5a058f" args="(double lambda, double gamma=1.0)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::decayWeights           </td>
          <td>(</td>
          <td class="paramtype">double&nbsp;</td>
          <td class="paramname"> <em>lambda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&nbsp;</td>
          <td class="paramname"> <em>gamma</em> = <code>1.0</code></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Multiplies all non-bias weights by (1.0 - (learning_rate * lambda)), starting with the output layer, and ending with the first hidden layer. Typical values for lambda are small (like 0.001.) After each layer, the value of lambda is multiplied by gamma. (If gamma is greater than 1.0, then weights in hidden layers will decay faster, and if gamma is less than 1.0, then weights in hidden layers will decay slower.) It may be significant to note that if a regularizing penalty is added to the error of lambda times the sum-squared values of non-bias weights, then on-line weight updating works out to the same as decaying the weights after each application of back-prop. 
<p>

</div>
</div><p>
<a class="anchor" name="d7aba05b75ee2d29d67bab3db14f5af7"></a><!-- doxytag: member="GClasses::GNeuralNet::dropNode" ref="d7aba05b75ee2d29d67bab3db14f5af7" args="(size_t layer, size_t node)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::dropNode           </td>
          <td>(</td>
          <td class="paramtype">size_t&nbsp;</td>
          <td class="paramname"> <em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&nbsp;</td>
          <td class="paramname"> <em>node</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Removes the specified node from the specified layer. (An exception will be thrown the layer only has one node.). 
<p>

</div>
</div><p>
<a class="anchor" name="3248753d965401e286e7c1faa6f6a706"></a><!-- doxytag: member="GClasses::GNeuralNet::enableIncrementalLearning" ref="3248753d965401e286e7c1faa6f6a706" args="(sp_relation &amp;pRelation, int labelDims, double *pMins, double *pRanges)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void GClasses::GNeuralNet::enableIncrementalLearning           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1smart__ptr.html">sp_relation</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>pRelation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>labelDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&nbsp;</td>
          <td class="paramname"> <em>pMins</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&nbsp;</td>
          <td class="paramname"> <em>pRanges</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
See the comment for <a class="el" href="class_g_classes_1_1_g_incremental_learner.html#c7c0a47f10dd10ef5cccab601e91ff37" title="You must call this method before you call trainIncremental pMins specifies the minimum...">GIncrementalLearner::enableIncrementalLearning</a>. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_incremental_learner.html#c7c0a47f10dd10ef5cccab601e91ff37">GClasses::GIncrementalLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="547fccef6ec0f6aad4d380bc4f1a0ef8"></a><!-- doxytag: member="GClasses::GNeuralNet::featureDims" ref="547fccef6ec0f6aad4d380bc4f1a0ef8" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual int GClasses::GNeuralNet::featureDims           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
See the comment for <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#fc302a31e9d5ef741343cf5659ba9a28" title="Returns the number of feature dims. Throws an exception if the model has not yet...">GSupervisedLearner::featureDims</a>. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#fc302a31e9d5ef741343cf5659ba9a28">GClasses::GSupervisedLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="09c2968b2e273de0cd0206e9b49c5349"></a><!-- doxytag: member="GClasses::GNeuralNet::forwardProp" ref="09c2968b2e273de0cd0206e9b49c5349" args="(const double *pRow)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::forwardProp           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pRow</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Evaluates a feature vector. (The results will be in the nodes of the output layer.). 
<p>

</div>
</div><p>
<a class="anchor" name="81c093fb25cbd640578099b715dc8a50"></a><!-- doxytag: member="GClasses::GNeuralNet::getLayer" ref="81c093fb25cbd640578099b715dc8a50" args="(int layer)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_g_classes_1_1_g_neural_net_layer.html">GNeuralNetLayer</a>&amp; GClasses::GNeuralNet::getLayer           </td>
          <td>(</td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>layer</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Returns a reference to the specified layer. 
<p>

</div>
</div><p>
<a class="anchor" name="e414e0b24c63e5a376d3ddaa0a0564b4"></a><!-- doxytag: member="GClasses::GNeuralNet::getRand" ref="e414e0b24c63e5a376d3ddaa0a0564b4" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a>* GClasses::GNeuralNet::getRand           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Returns the pseudo-random number generator associated with this object. 
<p>

</div>
</div><p>
<a class="anchor" name="9eb2d76976a334859f415ec494051a78"></a><!-- doxytag: member="GClasses::GNeuralNet::inputsToInternal" ref="9eb2d76976a334859f415ec494051a78" args="(const double *pExternal, double *pInternal)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::inputsToInternal           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pExternal</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&nbsp;</td>
          <td class="paramname"> <em>pInternal</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Convert all the input values to the internal representation. 
<p>

</div>
</div><p>
<a class="anchor" name="58402b48c8fa31a7a634b3ad2ea7ec72"></a><!-- doxytag: member="GClasses::GNeuralNet::internalTrainingData" ref="58402b48c8fa31a7a634b3ad2ea7ec72" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_g_classes_1_1_g_data.html">GData</a>* GClasses::GNeuralNet::internalTrainingData           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Gets the internal training data set. 
<p>

</div>
</div><p>
<a class="anchor" name="061bbccb9e77b571829aea44e0337c99"></a><!-- doxytag: member="GClasses::GNeuralNet::internalValidationData" ref="061bbccb9e77b571829aea44e0337c99" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_g_classes_1_1_g_data.html">GData</a>* GClasses::GNeuralNet::internalValidationData           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Gets the internal validation data set. 
<p>

</div>
</div><p>
<a class="anchor" name="926cf27b73c9fbed9136304a25122885"></a><!-- doxytag: member="GClasses::GNeuralNet::labelDims" ref="926cf27b73c9fbed9136304a25122885" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual int GClasses::GNeuralNet::labelDims           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
See the comment for <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#7d5d50de55dd9838f1caeab6e172d5aa" title="Returns the number of label dims. Throws an exception if the model has not yet been...">GSupervisedLearner::labelDims</a>. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#7d5d50de55dd9838f1caeab6e172d5aa">GClasses::GSupervisedLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="449d358ad9956d5fc61db21efe1a3942"></a><!-- doxytag: member="GClasses::GNeuralNet::layerCount" ref="449d358ad9956d5fc61db21efe1a3942" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">size_t GClasses::GNeuralNet::layerCount           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Returns the number of layers in this neural network. (Every network has at least one output layer, plus all of the hidden layers that you add by calling addLayer.). 
<p>

</div>
</div><p>
<a class="anchor" name="40d6982c5565bdb16711ab0361471614"></a><!-- doxytag: member="GClasses::GNeuralNet::learningRate" ref="40d6982c5565bdb16711ab0361471614" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double GClasses::GNeuralNet::learningRate           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Returns the current learning rate. 
<p>

</div>
</div><p>
<a class="anchor" name="aae62462d9be256a2a260c17eef4afbc"></a><!-- doxytag: member="GClasses::GNeuralNet::momentum" ref="aae62462d9be256a2a260c17eef4afbc" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double GClasses::GNeuralNet::momentum           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Returns the current momentum value. 
<p>

</div>
</div><p>
<a class="anchor" name="4c160f9a8f9c33fe7cd79720be6a421c"></a><!-- doxytag: member="GClasses::GNeuralNet::outputsToExternal" ref="4c160f9a8f9c33fe7cd79720be6a421c" args="(GPrediction *pExternal)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::outputsToExternal           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_prediction.html">GPrediction</a> *&nbsp;</td>
          <td class="paramname"> <em>pExternal</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Convert the internal output values to the external representation. 
<p>

</div>
</div><p>
<a class="anchor" name="d8c239a22c8e348f92f5fc1713a85808"></a><!-- doxytag: member="GClasses::GNeuralNet::outputsToInternal" ref="d8c239a22c8e348f92f5fc1713a85808" args="(const double *pExternal, double *pInternal)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::outputsToInternal           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pExternal</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&nbsp;</td>
          <td class="paramname"> <em>pInternal</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Convert all the output values to the internal representation pExternal points to the first external output value (so just the output part of the row). pInternal points to the first internal input value (so it's the whole internal row). 
<p>

</div>
</div><p>
<a class="anchor" name="85534d9115c3ab715d3043715e6c2145"></a><!-- doxytag: member="GClasses::GNeuralNet::perturbAllWeights" ref="85534d9115c3ab715d3043715e6c2145" args="(double deviation)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::perturbAllWeights           </td>
          <td>(</td>
          <td class="paramtype">double&nbsp;</td>
          <td class="paramname"> <em>deviation</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Perturbs all weights in the network by a random normal offset with the specified deviation. 
<p>

</div>
</div><p>
<a class="anchor" name="3b4eedbe12ff0e31974d8b53da9ee85b"></a><!-- doxytag: member="GClasses::GNeuralNet::predict" ref="3b4eedbe12ff0e31974d8b53da9ee85b" args="(const double *pIn, double *pOut)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void GClasses::GNeuralNet::predict           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pIn</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&nbsp;</td>
          <td class="paramname"> <em>pOut</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
See the comment for <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#369f9d2f11fae74b8183f656d9ca74c6" title="Evaluate pIn and compute a prediction for pOut.">GSupervisedLearner::predict</a>. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#369f9d2f11fae74b8183f656d9ca74c6">GClasses::GSupervisedLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="38d68ba2a901c40324d1c5eff2a15e59"></a><!-- doxytag: member="GClasses::GNeuralNet::predictDistribution" ref="38d68ba2a901c40324d1c5eff2a15e59" args="(const double *pIn, GPrediction *pOut)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void GClasses::GNeuralNet::predictDistribution           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pIn</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_prediction.html">GPrediction</a> *&nbsp;</td>
          <td class="paramname"> <em>pOut</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
See the comment for <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#45504ebdf2af63db0a7472b705db4a81" title="Evaluate pIn and compute a prediction for pOut. pOut is expected to point to an array...">GSupervisedLearner::predictDistribution</a>. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#45504ebdf2af63db0a7472b705db4a81">GClasses::GSupervisedLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="ed2999a007c3fcf02e484e9d87c627d5"></a><!-- doxytag: member="GClasses::GNeuralNet::releaseTrainingJunk" ref="ed2999a007c3fcf02e484e9d87c627d5" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::releaseTrainingJunk           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Some extra junk is allocated when training to make it efficient. This method is called when training is done to get rid of that extra junk. 
<p>

</div>
</div><p>
<a class="anchor" name="3abb685af4764fa0f0c34492799f91b1"></a><!-- doxytag: member="GClasses::GNeuralNet::setActivationFunction" ref="3abb685af4764fa0f0c34492799f91b1" args="(GActivationFunction *pSF, bool hold)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::setActivationFunction           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_activation_function.html">GActivationFunction</a> *&nbsp;</td>
          <td class="paramname"> <em>pSF</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&nbsp;</td>
          <td class="paramname"> <em>hold</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Sets the activation function to use with all subsequently added layers. (Note that the activation function for the output layer is set when train or enableIncrementalLearning is called, so if you only wish to set the squshing function for the output layer, call this method after all hidden layers have been added, but before you call train.) If hold is true, then the neural network will hold on to this instance of the activation function and delete it when the neural network is deleted. 
<p>

</div>
</div><p>
<a class="anchor" name="3942e81858018f7977e97a99fd222254"></a><!-- doxytag: member="GClasses::GNeuralNet::setBackPropTargetFunction" ref="3942e81858018f7977e97a99fd222254" args="(TargetFunction eTF)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::setBackPropTargetFunction           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_neural_net.html#3821c260c2cb0dbc64b6b0fbd0aabe84">TargetFunction</a>&nbsp;</td>
          <td class="paramname"> <em>eTF</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Specify the target function to use for back-propagation. The default is squared_error. cross_entropy tends to be faster, and is well-suited for classification tasks. 
<p>

</div>
</div><p>
<a class="anchor" name="2d02f321a6232f3b1640504c235655c9"></a><!-- doxytag: member="GClasses::GNeuralNet::setErrorOnOutputLayer" ref="2d02f321a6232f3b1640504c235655c9" args="(const double *pTarget, TargetFunction eTargetFunction=squared_error)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::setErrorOnOutputLayer           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pTarget</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_neural_net.html#3821c260c2cb0dbc64b6b0fbd0aabe84">TargetFunction</a>&nbsp;</td>
          <td class="paramname"> <em>eTargetFunction</em> = <code>squared_error</code></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method assumes that forwardProp has already been called. (Note that the predict method calls forwardProp). It computes the error values at each node in the output layer. After calling this method, it is typical to call <a class="el" href="class_g_classes_1_1_g_neural_net.html#fde11cca4167200c72b6567ef03b50fa" title="Returns the backprop object associated with this neural net (if there is one).">backProp()</a>-&gt;backpropagate(), to compute the error on the hidden nodes, and then to call <a class="el" href="class_g_classes_1_1_g_neural_net.html#fde11cca4167200c72b6567ef03b50fa" title="Returns the backprop object associated with this neural net (if there is one).">backProp()</a>-&gt;descendGradient to update the weights. pTarget contains the target values for the ouptut nodes. 
<p>

</div>
</div><p>
<a class="anchor" name="70096fc13b46b267fa137657f7b7a14c"></a><!-- doxytag: member="GClasses::GNeuralNet::setIterationsPerValidationCheck" ref="70096fc13b46b267fa137657f7b7a14c" args="(int n)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::setIterationsPerValidationCheck           </td>
          <td>(</td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>n</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Sets the number of iterations that will be performed before each time the network is tested again with the validation set to determine if we have a better best-set of weights, and whether or not it's achieved the termination condition yet. (An iteration is defined as a single pass through all rows in the training set.). 
<p>

</div>
</div><p>
<a class="anchor" name="bfdf6d4186899d5f508d32a336903594"></a><!-- doxytag: member="GClasses::GNeuralNet::setLearningRate" ref="bfdf6d4186899d5f508d32a336903594" args="(double d)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::setLearningRate           </td>
          <td>(</td>
          <td class="paramtype">double&nbsp;</td>
          <td class="paramname"> <em>d</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Set the learning rate. 
<p>

</div>
</div><p>
<a class="anchor" name="f383c68fff7a133b616d93020180015a"></a><!-- doxytag: member="GClasses::GNeuralNet::setMinImprovement" ref="f383c68fff7a133b616d93020180015a" args="(double d)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::setMinImprovement           </td>
          <td>(</td>
          <td class="paramtype">double&nbsp;</td>
          <td class="paramname"> <em>d</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Specifies the minimum improvement (as a ratio) that must be made since the last validation check for trainingn to continue. (For example, if the mean squared error at the previous validation check was 50, and the mean squared error at the current validation check is 49, then training will stop if d is &gt; 0.02.). 
<p>

</div>
</div><p>
<a class="anchor" name="3294a63458679248ed777c433ae3c66d"></a><!-- doxytag: member="GClasses::GNeuralNet::setMomentum" ref="3294a63458679248ed777c433ae3c66d" args="(double d)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::setMomentum           </td>
          <td>(</td>
          <td class="paramtype">double&nbsp;</td>
          <td class="paramname"> <em>d</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Momentum has the effect of speeding convergence and helping the gradient descent algorithm move past some local minimums. 
<p>

</div>
</div><p>
<a class="anchor" name="0f3e41a0e0e9e363e2398de2ba231f33"></a><!-- doxytag: member="GClasses::GNeuralNet::setValidationPortion" ref="0f3e41a0e0e9e363e2398de2ba231f33" args="(double d)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::setValidationPortion           </td>
          <td>(</td>
          <td class="paramtype">double&nbsp;</td>
          <td class="paramname"> <em>d</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Set the portion of the data that will be used for validation. If the value is 0, then all of the data is used for both training and validation. 
<p>

</div>
</div><p>
<a class="anchor" name="c7b2fc220e96389fc0cb4d3694d40a02"></a><!-- doxytag: member="GClasses::GNeuralNet::setWeights" ref="c7b2fc220e96389fc0cb4d3694d40a02" args="(const double *pWeights)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::setWeights           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pWeights</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Sets all the weights from an array of doubles. The number of doubles in the array can be determined by calling GetWeightCount(). 
<p>

</div>
</div><p>
<a class="anchor" name="4fc5b7d1e52af80cd3676a759e1bccc2"></a><!-- doxytag: member="GClasses::GNeuralNet::sumSquaredPredictionError" ref="4fc5b7d1e52af80cd3676a759e1bccc2" args="(const double *pTarget)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double GClasses::GNeuralNet::sumSquaredPredictionError           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pTarget</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method assumes forwardProp has been called. It computes the sum squared prediction error with the specified target vector. 
<p>

</div>
</div><p>
<a class="anchor" name="b0b1fe168491730483217ccccf6cf374"></a><!-- doxytag: member="GClasses::GNeuralNet::test" ref="b0b1fe168491730483217ccccf6cf374" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">static void GClasses::GNeuralNet::test           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [static]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Performs unit tests for this class. Throws an exception if there is a failure. 
<p>

</div>
</div><p>
<a class="anchor" name="1b0e9c9c17f8396138024f7bd4241c05"></a><!-- doxytag: member="GClasses::GNeuralNet::toTwt" ref="1b0e9c9c17f8396138024f7bd4241c05" args="(GTwtDoc *pDoc)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="class_g_classes_1_1_g_twt_node.html">GTwtNode</a>* GClasses::GNeuralNet::toTwt           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_twt_doc.html">GTwtDoc</a> *&nbsp;</td>
          <td class="paramname"> <em>pDoc</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Saves the model to a text file. (This doesn't save the short-term memory used for incremental learning, so if you're doing "incremental" learning, it will wake up with amnesia when you load it again.). 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#1a9fe000b02b63141e6fa3d1bfcbde11">GClasses::GSupervisedLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="934efa27b8fb84f51953d725e092700b"></a><!-- doxytag: member="GClasses::GNeuralNet::train" ref="934efa27b8fb84f51953d725e092700b" args="(GData *pData, int labelDims)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void GClasses::GNeuralNet::train           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *&nbsp;</td>
          <td class="paramname"> <em>pData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>labelDims</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Splits the provided data into a training and validation set and trains the network. To set the ratio, use SetTrainingPortion. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_supervised_learner.html#463f535faa6e719ecd3c50bd3c55471d">GClasses::GSupervisedLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="dfaf081a7b17988e868532ddd621a6e0"></a><!-- doxytag: member="GClasses::GNeuralNet::trainEpoch" ref="dfaf081a7b17988e868532ddd621a6e0" args="(GData *pTrainingData)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::trainEpoch           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *&nbsp;</td>
          <td class="paramname"> <em>pTrainingData</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Performs a single epoch of training. 
<p>

</div>
</div><p>
<a class="anchor" name="17ba800554377c60acf256741cabe82c"></a><!-- doxytag: member="GClasses::GNeuralNet::trainIncremental" ref="17ba800554377c60acf256741cabe82c" args="(const double *pIn, const double *pOut)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void GClasses::GNeuralNet::trainIncremental           </td>
          <td>(</td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pIn</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double *&nbsp;</td>
          <td class="paramname"> <em>pOut</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
See the comment for <a class="el" href="class_g_classes_1_1_g_incremental_learner.html#19b2d9edab4fbcb0fca825bc070dd156" title="Pass a single input row and the corresponding label to incrementally train this model...">GIncrementalLearner::trainIncremental</a>. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_incremental_learner.html#19b2d9edab4fbcb0fca825bc070dd156">GClasses::GIncrementalLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="30df9f3dbc0eee98c592acc990dcf130"></a><!-- doxytag: member="GClasses::GNeuralNet::trainSparse" ref="30df9f3dbc0eee98c592acc990dcf130" args="(GSparseMatrix *pData, int labelDims)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">virtual void GClasses::GNeuralNet::trainSparse           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_sparse_matrix.html">GSparseMatrix</a> *&nbsp;</td>
          <td class="paramname"> <em>pData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>labelDims</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
See the comment for <a class="el" href="class_g_classes_1_1_g_incremental_learner.html#72b760cfd5f35e6ba73203c65e5a13e3" title="Train using a sparse matrix. (Typically, implementations of this method will iterate...">GIncrementalLearner::trainSparse</a> Assumes all attributes are continuous. 
<p>

<p>Implements <a class="el" href="class_g_classes_1_1_g_incremental_learner.html#72b760cfd5f35e6ba73203c65e5a13e3">GClasses::GIncrementalLearner</a>.</p>

</div>
</div><p>
<a class="anchor" name="28cc2607f76d137b3d3bfe9c8852bc4c"></a><!-- doxytag: member="GClasses::GNeuralNet::trainWithValidation" ref="28cc2607f76d137b3d3bfe9c8852bc4c" args="(GData *pTrainingData, GData *pValidationData, int labelDims)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int GClasses::GNeuralNet::trainWithValidation           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *&nbsp;</td>
          <td class="paramname"> <em>pTrainingData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *&nbsp;</td>
          <td class="paramname"> <em>pValidationData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>labelDims</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Train the network until the termination condition is met. Returns the number of epochs required to train it. 
<p>

</div>
</div><p>
<a class="anchor" name="ff4b7ef75957d163158c37a3f30738da"></a><!-- doxytag: member="GClasses::GNeuralNet::validationSquaredError" ref="ff4b7ef75957d163158c37a3f30738da" args="(GData *pValidationData)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double GClasses::GNeuralNet::validationSquaredError           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_g_classes_1_1_g_data.html">GData</a> *&nbsp;</td>
          <td class="paramname"> <em>pValidationData</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [protected]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Measures the sum squared error against the specified dataset. 
<p>

</div>
</div><p>
<a class="anchor" name="48f738fa5bc10067b2901cc12624e3bb"></a><!-- doxytag: member="GClasses::GNeuralNet::weights" ref="48f738fa5bc10067b2901cc12624e3bb" args="(double *pOutWeights)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void GClasses::GNeuralNet::weights           </td>
          <td>(</td>
          <td class="paramtype">double *&nbsp;</td>
          <td class="paramname"> <em>pOutWeights</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Serializes the network weights into an array of doubles. The number of doubles in the array can be determined by calling GetWeightCount(). 
<p>

</div>
</div><p>
<hr><h2>Friends And Related Function Documentation</h2>
<a class="anchor" name="fd0d02db90315bd84b88cc5924a29053"></a><!-- doxytag: member="GClasses::GNeuralNet::GBackProp" ref="fd0d02db90315bd84b88cc5924a29053" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">friend class <a class="el" href="class_g_classes_1_1_g_back_prop.html">GBackProp</a><code> [friend]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<hr><h2>Member Data Documentation</h2>
<a class="anchor" name="b2b1de8a28c9229f2fb42f072178b141"></a><!-- doxytag: member="GClasses::GNeuralNet::m_activationFunctions" ref="b2b1de8a28c9229f2fb42f072178b141" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;<a class="el" href="class_g_classes_1_1_g_activation_function.html">GActivationFunction</a>*&gt; <a class="el" href="class_g_classes_1_1_g_neural_net.html#b2b1de8a28c9229f2fb42f072178b141">GClasses::GNeuralNet::m_activationFunctions</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="7ba6d45b553272733e346939220d7557"></a><!-- doxytag: member="GClasses::GNeuralNet::m_backPropTargetFunction" ref="7ba6d45b553272733e346939220d7557" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_g_classes_1_1_g_neural_net.html#3821c260c2cb0dbc64b6b0fbd0aabe84">TargetFunction</a> <a class="el" href="class_g_classes_1_1_g_neural_net.html#7ba6d45b553272733e346939220d7557">GClasses::GNeuralNet::m_backPropTargetFunction</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="e441221ff1fad1d68fc4345419149ed1"></a><!-- doxytag: member="GClasses::GNeuralNet::m_epochsPerValidationCheck" ref="e441221ff1fad1d68fc4345419149ed1" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="class_g_classes_1_1_g_neural_net.html#e441221ff1fad1d68fc4345419149ed1">GClasses::GNeuralNet::m_epochsPerValidationCheck</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="0efb3a73fccebcb8b16dfc9254c7c021"></a><!-- doxytag: member="GClasses::GNeuralNet::m_featureDims" ref="0efb3a73fccebcb8b16dfc9254c7c021" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="class_g_classes_1_1_g_neural_net.html#0efb3a73fccebcb8b16dfc9254c7c021">GClasses::GNeuralNet::m_featureDims</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="78f1a3faf8095eeb5b95626dbda5caea"></a><!-- doxytag: member="GClasses::GNeuralNet::m_labelDims" ref="78f1a3faf8095eeb5b95626dbda5caea" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="class_g_classes_1_1_g_neural_net.html#78f1a3faf8095eeb5b95626dbda5caea">GClasses::GNeuralNet::m_labelDims</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="92c3817e46a09eb23dc7e8b511c527e0"></a><!-- doxytag: member="GClasses::GNeuralNet::m_layers" ref="92c3817e46a09eb23dc7e8b511c527e0" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;<a class="el" href="class_g_classes_1_1_g_neural_net_layer.html">GNeuralNetLayer</a>&gt; <a class="el" href="class_g_classes_1_1_g_neural_net.html#92c3817e46a09eb23dc7e8b511c527e0">GClasses::GNeuralNet::m_layers</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="860d67144206d666e8823554ad59e004"></a><!-- doxytag: member="GClasses::GNeuralNet::m_learningRate" ref="860d67144206d666e8823554ad59e004" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double <a class="el" href="class_g_classes_1_1_g_neural_net.html#860d67144206d666e8823554ad59e004">GClasses::GNeuralNet::m_learningRate</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="1373365847eba4087b4578a781455bd4"></a><!-- doxytag: member="GClasses::GNeuralNet::m_minImprovement" ref="1373365847eba4087b4578a781455bd4" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double <a class="el" href="class_g_classes_1_1_g_neural_net.html#1373365847eba4087b4578a781455bd4">GClasses::GNeuralNet::m_minImprovement</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="a91d9ff41ea8cf0bf9aebd5c38eaffc4"></a><!-- doxytag: member="GClasses::GNeuralNet::m_momentum" ref="a91d9ff41ea8cf0bf9aebd5c38eaffc4" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double <a class="el" href="class_g_classes_1_1_g_neural_net.html#a91d9ff41ea8cf0bf9aebd5c38eaffc4">GClasses::GNeuralNet::m_momentum</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="266df7e66c43efb5413edef8c1bd2356"></a><!-- doxytag: member="GClasses::GNeuralNet::m_pActivationFunction" ref="266df7e66c43efb5413edef8c1bd2356" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_g_classes_1_1_g_activation_function.html">GActivationFunction</a>* <a class="el" href="class_g_classes_1_1_g_neural_net.html#266df7e66c43efb5413edef8c1bd2356">GClasses::GNeuralNet::m_pActivationFunction</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="cc73a2f7b836adec6ce7fadcf15520f5"></a><!-- doxytag: member="GClasses::GNeuralNet::m_pBackProp" ref="cc73a2f7b836adec6ce7fadcf15520f5" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_g_classes_1_1_g_back_prop.html">GBackProp</a>* <a class="el" href="class_g_classes_1_1_g_neural_net.html#cc73a2f7b836adec6ce7fadcf15520f5">GClasses::GNeuralNet::m_pBackProp</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="c30372cfb8f73597234cc54df72d5d60"></a><!-- doxytag: member="GClasses::GNeuralNet::m_pRand" ref="c30372cfb8f73597234cc54df72d5d60" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_g_classes_1_1_g_rand.html">GRand</a>* <a class="el" href="class_g_classes_1_1_g_neural_net.html#c30372cfb8f73597234cc54df72d5d60">GClasses::GNeuralNet::m_pRand</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
<a class="anchor" name="df2792b6c57bc14e309f4d3f57bd259c"></a><!-- doxytag: member="GClasses::GNeuralNet::m_validationPortion" ref="df2792b6c57bc14e309f4d3f57bd259c" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double <a class="el" href="class_g_classes_1_1_g_neural_net.html#df2792b6c57bc14e309f4d3f57bd259c">GClasses::GNeuralNet::m_validationPortion</a><code> [protected]</code>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>

</div>
</div><p>
</div>
<hr size="1"><address style="text-align: right;"><small>Generated on Tue Nov 2 14:18:24 2010 for GClasses by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.8 </small></address>
</body>
</html>
